@inbook{Zitzler1998,
abstract = {Since 1985 various evolutionary approaches to multiobjective optimization have been developed, capable of searching for multiple solutions concurrently in a single run. But the few comparative studies of different methods available to date are mostly qualitative and restricted to two approaches. In this paper an extensive, quantitative comparison is presented, applying four multiobjective evolutionary algorithms to an extended 0/1 knapsack problem.},
address = {Berlin, Heidelberg},
author = {Zitzler, Eckart and Thiele, Lothar},
doi = {10.1007/BFb0056872},
editor = {Eiben, Agoston E and B{\"{a}}ck, Thomas and Schoenauer, Marc and Schwefel, Hans-Paul},
isbn = {978-3-540-65078-2, 978-3-540-49672-4},
pages = {292--301},
publisher = {Springer Berlin Heidelberg},
title = {{Multiobjective optimization using evolutionary algorithms — A comparative case study}},
year = {1998}
}

@proceedings{Okabe:je,
author = {Okabe, T and Jin, Y and Sendhoff, B},
keywords = {moea},
mendeley-groups = {TSC},
pages = {878--885},
title = {{A Critical Survey of Performance Indices for Multi-Objective Optimisation}},
year = {2003}
}

@article{kamjoo2016multi,
author = {Kamjoo, Azadeh and Maheri, Alireza and Dizqah, Arash M and Putrus, Ghanim a},
doi = {10.1016/j.ijepes.2015.07.007},
issn = {0142-0615},
journal = {International Journal of Electrical Power and Energy Systems},
keywords = {multi-objective optimisation},
pages = {187--194},
publisher = {Elsevier},
title = {{Electrical Power and Energy Systems Multi-objective design under uncertainties of hybrid renewable energy system using NSGA-II and chance constrained programming}},
volume = {74},
year = {2016}
}
@article{tuladhar2016multi,
author = {Ongsakul, Weerakorn and Singh, Jai Govind and Tuladhar, Subas Ratna},
doi = {10.1049/iet-gtd.2015.0587},
issn = {1751-8687},
journal = {IET Generation, Transmission {\&} Distribution},
number = {12},
pages = {2842--2851},
publisher = {IET},
title = {{Multi-objective approach for distribution network reconfiguration with optimal DG power factor using NSPSO}},
volume = {10},
year = {2016}
}
@article{senouci2016static,
abstract = {A major issue in designing wireless sensor networks is the deployment problem. Indeed, many performances of the sensor network, such as coverage, are determined by the number and locations of deployed sensors. This paper reviews existing deterministic deployment strategies and devises a modified binary particle swarm optimization, which adopts a new position updating procedure for a faster convergence and exploits the abandonment concept to avoid some drawbacks such as premature convergence. The devised approach combines, in a meaningful way, the characteristics of the binary particle swarm optimization with the wireless sensor networks deployment requirements in order to devise a lightweight and efficient sensor placement algorithm. The effectiveness and efficiency of the proposed approach are evaluated through extensive simulations. The obtained results show that the proposed algorithm outperforms the state-of-the-art approaches, especially in the case of preferential coverage. Copyright {\textcopyright} 2015 John Wiley {\&} Sons, Ltd.},
author = {Senouci, Mustapha R. and Bouguettouche, Daoud and Souilah, Farouk and Mellouk, Abdelhamid},
doi = {10.1002/dac.3040},
issn = {10991131},
journal = {International Journal of Communication Systems},
keywords = {coverage,deterministic deployment,particle swarm optimization,sensor placement,wireless sensor networks},
number = {5},
pages = {1026--1041},
publisher = {Wiley Online Library},
title = {{Static wireless sensor networks deployment using an improved binary PSO}},
volume = {29},
year = {2016}
}
@inproceedings{hassan2005comparison,
author = {Hassan, R and Cohanim, B and de Weck, O},
pages = {1897},
title = {{A Comparison of Particle Swarm Optimization and the Genetic Algorithm}},
year = {2005}
}
@article{mladenovic2007p,
abstract = {The p-median problem is one of the basic models in discrete location theory. As with most location problems, it is classified as NP-hard, and so, heuristic methods are usually used to solve it. Metaheuristics are frameworks for building heuristics. In this survey, we examine the p-median, with the aim of providing an overview on advances in solving it using recent procedures based on metaheuristic rules. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Mladenovi{\'{c}}, Nenad and Brimberg, Jack and Hansen, Pierre and Moreno-P{\'{e}}rez, Jos{\'{e}} A.},
doi = {10.1016/j.ejor.2005.05.034},
isbn = {0377-2217},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Location,Metaheuristics,p-Median},
number = {3},
pages = {927--939},
publisher = {Elsevier},
title = {{The p-median problem: A survey of metaheuristic approaches}},
volume = {179},
year = {2007}
}
@article{li2005integration,
abstract = {Optimal location search is frequently required in many urban applications for siting one or more facilities. However, the search may become very complex when it involves multiple sites, various constraints and multiple-objectives. The exhaustive blind (brute-force) search with high-dimensional spatial data is infeasible in solving optimization problems because of a huge combinatorial solution space. Inteligent search algorithms can help to improve the performance of spatial search. This study will demonstrate that genetic algorithms can be used with Geographical Information systems (GIS) to effectively solve the spatial decision problems for optimally sitting n sites of a facility. Detailed population and transportation data from GIS are used to facilitate the calculation of fitness functions. Multiple planning objectives are also incorporated in the GA program. Experiments indicate that the proposed method has much better performance than simulated annealing and GIS neighborhood search methods. The GA method is very convenient in finding the solution with the highest utility value. {\textcopyright} 2005 Taylor {\&} Francis Group Ltd.},
author = {Li, Xia and Yeh, Anthony Gar On},
doi = {10.1080/13658810500032388},
isbn = {1365-8816},
issn = {13658816},
journal = {International Journal of Geographical Information Science},
keywords = {GIS,Genetic algorithms,Multiple objectives,Optimal location,Simulated annealing},
number = {5},
pages = {581--601},
publisher = {Taylor {\&} Francis},
title = {{Integration of genetic algorithms and GIS for optimal location search}},
volume = {19},
year = {2005}
}
@article{landset2015survey,
abstract = {With an ever-increasing amount of options, the task of selecting machine learning tools for big data can be difficult. The available tools have advantages and drawbacks, and many have overlapping uses. The world's data is growing rapidly, and traditional tools for machine learning are becoming insufficient as we move towards distributed and real-time processing. This paper is intended to aid the researcher or professional who understands machine learning but is inexperienced with big data. In order to evaluate tools, one should have a thorough understanding of what to look for. To that end, this paper provides a list of criteria for making selections along with an analysis of the advantages and drawbacks of each. We do this by starting from the beginning, and looking at what exactly the term “big data” means. From there, we go on to the Hadoop ecosystem for a look at many of the projects that are part of a typical machine learning architecture and an understanding of how everything might fit together. We discuss the advantages and disadvantages of three different processing paradigms along with a comparison of engines that implement them, including MapReduce, Spark, Flink, Storm, and H$\backslash$r$\backslash$n                   2$\backslash$r$\backslash$n                O. We then look at machine learning libraries and frameworks including Mahout, MLlib, SAMOA, and evaluate them based on criteria such as scalability, ease of use, and extensibility. There is no single toolkit that truly embodies a one-size-fits-all solution, so this paper aims to help make decisions smoother by providing as much information as possible and quantifying what the tradeoffs will be. Additionally, throughout this paper, we review recent research in the field using these tools and talk about possible future directions for toolkit-based learning.},
author = {Landset, Sara and Khoshgoftaar, Taghi M. and Richter, Aaron N. and Hasanin, Tawfiq},
doi = {10.1186/s40537-015-0032-1},
isbn = {21961115 (Linking)},
issn = {2196-1115},
journal = {Journal of Big Data},
number = {1},
pages = {24},
publisher = {Springer International Publishing},
title = {{A survey of open source tools for machine learning with big data in the Hadoop ecosystem}},
volume = {2},
year = {2015}
}
@article{curbera2002unraveling,
abstract = {O ver the past few years, businesses have interacted using ad hoc approaches that take advantage of the basic Internet infra-structure. Now, however, Web services are emerg-ing to provide a systematic and extensible frame-work for application-to-application interaction, built on top of existing Web protocols and based on open XML standards. Say, for example, that you want to purchase a vacation package using an online travel agent. To locate the best prices on airline tickets, hotels, and rental cars, the agency will have to poll multiple companies, each of which likely uses different, incompatible applications for pricing and reserva-tions. Web services aim to simplify this process by defining a standardized mechanism to describe, locate, and communicate with online applications. Essentially, each application becomes an accessible Web service component that is described using open standards. An online travel service could thus use the same Web services framework to locate and reserve your package elements, as well as to lease Internet-based credit check and bank payment ser-vices on a pay-per-use basis to expedite fund trans-fers between you, the travel agency, and the vendors. The Web services framework is divided into three areas — communication protocols, service descriptions, and service discovery — and specifi-cations are being developed for each. In this arti-cle, we look at the specifications that are current-ly the most salient and stable in each area: I the simple object access protocol (SOAP, www.w3.org/2000/xp) which enables commu-nication among Web services; I the Web Services Description Language (WSDL, www.w3.org/TR/wsdl.html), which provides a formal, computer-readable description of Web services; and I the Universal Description, Discovery, and Inte-gration (UDDI, www.uddi.org) directory, which is a registry of Web services descriptions. At this point, Web services technology is still emerging, and researchers are still developing important pieces, including quality of service descriptions and interaction models. Because the Web services framework is modular, however, you can use just the parts of the stack you need. There-fore, developers can take advantage of the avail-able specifications and tooling now and incorpo-rate more modules as the technology matures.},
author = {Curbera, Francisco and Duftler, Matthew and Khalaf, Rania and Nagy, William and Mukhi, Nirmal and Weerawarana, Sanjiva},
doi = {10.1109/4236.991449},
isbn = {1089-7801},
issn = {10897801},
journal = {IEEE Internet Computing},
number = {2},
pages = {86--93},
publisher = {IEEE},
title = {{Unraveling the Web services Web: An introduction to SOAP, WSDL, and UDDI}},
volume = {6},
year = {2002}
}
@article{5235136,
abstract = {The goal of service oriented architectures (SOAs) is to enable the creation of business applications through the automatic discovery and composition of independently developed and deployed (Web) services. Automatic discovery of Web services (WSs) can be achieved by incorporating semantics into a richer WS description model (WSDM) and by the use of semantic Web (SW) technologies in the WS matchmaking and selection (i.e., discovery) process. A sufficiently rich WSDM should encompass not only functional but also nonfunctional aspects like quality of service (QoS). QoS is a set of performance and domain-dependent attributes that has a substantial impact on WS requesters' expectations. Thus, it can be used for distinguishing between many functionally equivalent WSs that are available nowadays. This paper starts by defining QoS in the context of WSs. Its main contribution is the analysis of the requirements for a semantically rich QoS-based WSDM and an accurate, effective QoS-based WS Discovery (WSDi) process. In addition, a road map of extending current WS standard technologies for realizing semantic, functional, and QoS-based WSDi, respecting the above requirements, is presented.},
author = {Kritikos, Kyriakos and Plexousakis, Dimitris},
doi = {10.1109/TSC.2009.26},
isbn = {9780769528700},
issn = {19391374},
journal = {IEEE Transactions on Services Computing},
keywords = {Constraint programming,QoS modeling,Quality of service,Requirements engineering,Service discovery,Service matchmaking,Service selection,Web services,Web-based services},
month = {oct},
number = {4},
pages = {320--337},
title = {{Requirements for QoS-based Web service description and discovery}},
volume = {2},
year = {2009}
}
@inproceedings{4317873,
abstract = {Discovering Web services using keyword-based search techniques offered by existing UDDI APIs (i.e. Inquiry API) may not yield results that are tailored to clients' needs. When discovering Web services, clients look for those that meet their requirements, primarily the overall functionality and quality of service (QoS). Standards such as UDDI, WSDL, and SOAP have the potential of providing QoS-aware discovery, however, there are technical challenges associated with existing standards such as the client's ability to control and manage discovery of Web services across accessible service registries. This paper proposes a solution to this problem and introduces the Web service relevancy function (WsRF) used for measuring the relevancy ranking of a particular Web service based on client's preferences, and QoS metrics. We present experimental validation, results, and analysis of the presented ideas.},
author = {Al-Masri, Eyhab and Mahmoud, Qusay H.},
doi = {10.1109/ICCCN.2007.4317873},
isbn = {9781424412518},
issn = {10952055},
keywords = {Discovery of Web services,QoS,Qualify of service,Ranking,Ranking of Web services,Service registries,UDDI,Web service broker,Web services},
month = {aug},
pages = {529--534},
title = {{QoS-based discovery and ranking of Web services}},
year = {2007}
}
@article{yue2004underlying,
abstract = {With the rapid development of e-business, web applications based on the Web are developed from localization to globalization, from B2C(business-to-customer) to B2B(business-to-business), from centralized fashion to decentralized fashion. Web service is a new application model for decentralized computing, and it is also an effective mechanism for the data and service integration on the web. Thus, web service has become a solution to e-business. It is important and necessary to carry out the research on the new architecture of web services, on the combinations with other good techniques, and on the integration of services. A survey presents on various aspects of the research of web services from the basic concepts to the principal research problems and the underlying techniques, including data integration in web services, web service composition, semantic web service, web service discovery, web service security, the solution to web services in the P2P (Peer-to-Peer) computing environment, and the grid service, etc. This paper also presents a summary of the current art of the state of these techniques, a discussion on the future research topics, and the challenges of the web services.},
author = {Yue, K and Wang, X L and Zhou, A Y},
isbn = {1341528X},
issn = {10009825},
journal = {Ruan Jian Xue Bao/Journal of Software},
keywords = {Grid,P2P,Security,Semantic Web,Service composition,Service discovery,Web service},
number = {3},
pages = {428--442},
publisher = {Beijing},
title = {{Underlying techniques for web services: A survey}},
volume = {15},
year = {2004}
}
@article{Ran,
abstract = {Web services technology has generated a lot interest, but its adoption rate has been slow. This paper discusses issues related to this slow take up and argues that quality of services is one of the contributing factors. The paper proposes a new Web services discovery model in which the functional and non-functional requirements (i.e. quality of services) are taken into account for the service discovery. The proposed model should give Web services consumers some confidence about the quality of service of the discovered Web services.},
author = {Ran, Shuping},
doi = {10.1145/844357.844360},
isbn = {1551-9031},
issn = {15519031},
journal = {ACM SIGecom Exchanges},
keywords = { UDDI extension, model, quality of services, tModel, web services discovery,UDDI},
number = {1},
pages = {1--10},
publisher = {ACM},
title = {{A model for web services discovery with QoS}},
volume = {4},
year = {2003}
}
@article{zhang2007moea,
abstract = {Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper.},
author = {Zhang, Q. and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
isbn = {1089-778X VO - 11},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Computational complexity,Pareto optimality,decomposition,evolutionary algorithm,multiobjective optimization},
number = {6},
pages = {712--731},
publisher = {IEEE},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}
@article{chen2014web,
author = {Gonsalves, Blessina},
isbn = {9781509025527},
journal = {IEEE transactions on parallel and distributed systems},
keywords = {as memory-based algorithms and,cf algorithm is one,collaborative filtering,data sparsity,it is further classified,machine,model-,of popular recommendation algorithm,quality of service,support vector},
number = {Icices},
pages = {1--11},
publisher = {IEEE},
title = {{Improved Web Service Recommendation via Exploiting Location and QoS Information}},
volume = {25},
year = {2016}
}
@article{7108071,
author = {Liu, Jianxun and Tang, Mingdong and Zheng, Zibin and Liu, Xiaoqing Frank and Lyu, Saixia},
doi = {10.1109/TSC.2015.2433251},
isbn = {1939-1374},
issn = {19391374},
journal = {IEEE Transactions on Services Computing},
keywords = {QoS prediction,Web services,collaborative filtering,location-aware,service recommendation},
month = {sep},
number = {5},
pages = {686--699},
title = {{Location-Aware and Personalized Collaborative Filtering for Web Service Recommendation}},
volume = {9},
year = {2016}
}
@incollection{Multiobjective,
author = {Deb, Kalyanmoy and Deb, Kalyanmoy},
doi = {10.1007/978-1-4614-6940-7_15},
isbn = {978-1-84800-381-1},
issn = {07384602},
pages = {403--449},
publisher = {Springer London},
title = {{Multi-objective Optimization}},
year = {2014}
}
@article{Johansson,
abstract = {Research in distributed database systems to date has assumed a ``variable cost'' model of network response time. However, network response time has two components: transmission time (variable with message size) and latency (fixed). This research improves on existing models by incorporating a ``fixed plus variable cost'' model of the network response time. In this research, we:},
author = {Johansson, Jesper M},
doi = {10.1023/A:1019121024410},
issn = {1573-7667},
journal = {Information Technology and Management},
keywords = { latency, network design, network response time, parallel processing,distributed database systems},
number = {3},
pages = {183--194},
publisher = {Kluwer Academic Publishers},
title = {{On the impact of network latency on distributed systems design}},
volume = {1},
year = {2000}
}
@article{Aboolian,
abstract = {Web Services have become a viable component technology in distributed e-commerce platforms. Due to the move to high-speed Internet communication and tremendous increases in computing power, network latency has begun to play a more important role in determining service response time. Hence, the locations of a Web Services provider's facilities, customer allocation, and the number of servers at each facility have a significant impact on its performance and customer satisfaction. In this paper we introduce a location-allocation model for a Web Services provider in a duopoly competitive market. Demands for services of these servers are available at each node of a network, and a subset of nodes is to be chosen to locate one or more servers in each. The objective is to maximize the provider's profit. The problem is formulated and analyzed. An exact solution approach is developed and the results of its efficiency are reported. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Aboolian, Robert and Sun, Yi and Koehler, Gary J.},
doi = {10.1016/j.ejor.2007.11.057},
isbn = {0377-2217},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Competitive facility location models,Nonlinear integer programming,Web Services},
number = {1},
pages = {64--77},
title = {{A location-allocation problem for a web services provider in a competitive market}},
volume = {194},
year = {2009}
}
@inproceedings{5552800,
abstract = {Quality-of-Service (QoS) is widely employed for describing non-functional characteristics of Web services. Although QoS of Web services has been investigated in a lot of previous works, there is a lack of real-world Web service QoS datasets for validating new QoS based techniques and models of Web services. To study the performance of real-world Web services as well as provide reusable research datasets for promoting the research of QoS-driven Web services, we conduct several large-scale evaluations on real-world Web services. Firstly, addresses of 21,358 Web services are obtained from the Internet. Then, invocation failure probability performance of 150 Web services is assessed by 100 distributed service users. After that, response time and throughput performance of 5,825 Web services are evaluated by 339 distributed service users. Detailed experimental results are presented in this paper and comprehensive Web service QoS datasets are publicly released for future research.},
author = {Zheng, Zibin and Zhang, Yilei and Lyu, Michael R.},
doi = {10.1109/ICWS.2010.10},
isbn = {9780769541280},
keywords = {Internet;Web services;quality of service;Internet;distributed {\{}QoS{\}} evaluation;real world Web services;reusable research datasets;Java;Logic gates;Probability;Quality of service;Servers;Web services;Distributed Evaluation;{\{}QoS{\}};Web Service},
pages = {83--90},
title = {{Distributed QoS evaluation for real-world Web services}},
year = {2010}
}
@incollection{EnhancedGenetic,
author = {Huang, Hai and Ma, Hui and Zhang, Mengjie},
doi = {10.1007/978-3-319-10085-2_20},
isbn = {9783319100845},
issn = {16113349},
number = {PART 2},
pages = {223--230},
publisher = {Springer International Publishing},
title = {{An enhanced genetic algorithm for web service location-allocation}},
volume = {8645 LNCS},
year = {2014}
}
@inproceedings{7360024,
abstract = {Evolutionary algorithms are relatively new, but very powerful techniques used to find solutions to many real-world search and optimization problems. Many of these problems have multiple objectives, which leads to the need to obtain a set of optimal solutions, known as effective solutions. It has been found that using evolutionary algorithms is a highly effective way of finding multiple effective solutions in a single simulation run. Comprehensive coverage of this growing area of research Carefully introduces each algorithm with examples and in-depth discussion Includes many applications to real-world problems, including engineering design and scheduling Includes discussion of advanced topics and future research Can be used as a course text or for self-study Accessible to those with limited knowledge of classical multi-objective optimization and evolutionary algorithms The integrated presentation of theory, algorithms and examples will benefit those working and researching in the areas of optimization, optimal design and evolutionary computing. This text provides an excellent introduction to the use of evolutionary algorithms in multi-objective optimization, allowing use as a graduate course text or for self-study.},
author = {Riquelme, Nery and {Von Lucken}, Christian and Baran, Benjamin},
doi = {10.1109/CLEI.2015.7360024},
isbn = {978-1-4673-9143-6},
issn = {1089778X},
keywords = {optimisation;epsilon indicator;hypervolume;inverte},
mendeley-groups = {TSC},
month = {oct},
pages = {1--11},
pmid = {12336134},
title = {{Performance metrics in multi-objective optimization}},
year = {2015}
}


@inproceedings{distanceMetrics,
abstract = {We consider and compare four Internet distance metrics and analyzethe predictive power of these metrics in selecting, from a givensource, the lowest latency destination from among a candidate set.The four metrics are: IP path length; autonomous system (AS) pathlength; great circle geographic distance; and previously measuredround trip time (RTT). We describe general properties of these fourmetrics and, using an unprecedented volume of real Internet macroscopictopology and RTT data, compare their correlation with actual RTTto the destination. The new methodology we propose for testing differentmetrics is suitable for evaluating new distance estimation techniquesas they become available.},
address = {Brazil},
author = {Huffaker, Bradley and Fomenkov, Marina and Plummer, Daniel J. and Moore, David},
keywords = {active data analysis topology},
month = {sep},
pages = {1--6},
publisher = {IEEE},
title = {{Distance Metrics in the Internet}},
year = {2002}
}
@incollection{MultiobjectiveOptimization,
author = {Zaroliagis, Christos},
isbn = {978-3-540-29498-6},
pages = {45--47},
publisher = {Springer Berlin Heidelberg},
title = {{Recent Advances in Multiobjective Optimization}},
volume = {3777},
year = {2005}
}
@article{Zhou201132,
abstract = {A multiobjective optimization problem involves several conflicting objectives and has a set of Pareto optimal solutions. By evolving a population of solutions, multiobjective evolutionary algorithms (MOEAs) are able to approximate the Pareto optimal set in a single run. MOEAs have attracted a lot of research effort during the last 20 years, and they are still one of the hottest research areas in the field of evolutionary computation. This paper surveys the development of MOEAs primarily during the last eight years. It covers algorithmic frameworks such as decomposition-based MOEAs (MOEA/Ds), memetic MOEAs, coevolutionary MOEAs, selection and offspring reproduction operators, MOEAs with specific search methods, MOEAs for multimodal problems, constraint handling and MOEAs, computationally expensive multiobjective optimization problems (MOPs), dynamic MOPs, noisy MOPs, combinatorial and discrete MOPs, benchmark problems, performance indicators, and applications. In addition, some future research issues are also presented.},
author = {Zhou, Aimin and Qu, Bo-Yang and Li, Hui and Zhao, Shi-Zheng and Suganthan, Ponnuthurai Nagaratnam and Zhang, Qingfu},
doi = {10.1016/j.swevo.2011.03.001},
isbn = {2210-6502},
issn = {22106502},
journal = {Swarm and Evolutionary Computation},
keywords = {Evolutionary multiobjective optimization,Multicriteria decision making,Multiobjective evolutionary algorithms,Multiobjective optimization},
number = {1},
pages = {32--49},
title = {{Multiobjective evolutionary algorithms: A survey of the state of the art}},
volume = {1},
year = {2011}
}
@article{key:article,
author = {Desai, Sneha},
journal = {International Journal of Computer Applications},
keywords = {bio-inspired 2d spider-,crete mechanics optimal control,dis-,non-dominated sorting genetic algorithm,optimization},
number = {20},
pages = {14--20},
title = {{Multi-Objective Constrained Optimization using Discrete Mechanics and NSGA-II Approach}},
volume = {57},
year = {2012}
}
@inproceedings{Liu,
abstract = {The emerging Service-Oriented Computing (SOC) paradigm promises to enable businesses and organizations to collaborate in an unprecedented way by means of standard web services. To support rapid and dynamic composition of services in this paradigm, web services that meet requesters' functional requirements must be able to be located and bounded dynamically from a large and constantly changing number of service providers based on their Quality of Service (QoS). In order to enable quality-driven web service selection, we need an open, fair, dynamic and secure framework to evaluate the QoS of a vast number of web services. The fair computation and enforcing of QoS of web services should have minimal overhead but yet able to achieve sufficient trust by both service requesters and providers. In this paper, we presented our open, fair and dynamic QoS computation model for web services selection through implementation of and experimentation with a QoS registry in a hypothetical phone service provisioning market place application.},
author = {Liu, Yutu and Ngu, Anne H. and Zeng, Liang Z.},
doi = {10.1145/1013367.1013379},
isbn = {1581139128},
issn = {00336807},
keywords = { extensible QoS model, ranking of QoS, web services,QoS},
pages = {66},
publisher = {ACM},
title = {{QoS computation and policing in dynamic web service selection}},
year = {2004}
}
@article{Deb,
abstract = {Since the suggestion of a computing procedure of multiple Pareto-optimal solutions in multi-objective optimization problems in the early Nineties, researchers have been on the look out for a procedure which is computationally fast and simultaneously capable of finding a well-converged and well-distributed set of solutions. Most multi-objective evolutionary algorithms (MOEAs) developed in the past decade are either good for achieving a well-distributed solutions at the expense of a large computational effort or computationally fast at the expense of achieving a not-so-good distribution of solutions. For example, although the Strength Pareto Evolutionary Algorithm or SPEA (Zitzler and Thiele, 1999) produces a much better distribution compared to the elitist non-dominated sorting GA or NSGA-II (Deb et al., 2002a), the computational time needed to run SPEA is much greater. In this paper, we evaluate a recently-proposed steady-state MOEA (Deb et al., 2003) which was developed based on the epsilon-dominance concept introduced earlier(Laumanns et al., 2002) and using efficient parent and archive update strategies for achieving a well-distributed and well-converged set of solutions quickly. Based on an extensive comparative study with four other state-of-the-art MOEAs on a number of two, three, and four objective test problems, it is observed that the steady-state MOEA is a good compromise in terms of convergence near to the Pareto-optimal front, diversity of solutions, and computational time. Moreover, the epsilon-MOEA is a step closer towards making MOEAs pragmatic, particularly allowing a decision-maker to control the achievable accuracy in the obtained Pareto-optimal solutions.},
author = {Deb, Kalyanmoy and Mohan, Manikanth and Mishra, Shikhar},
doi = {10.1162/106365605774666895},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
number = {4},
pages = {501--525},
pmid = {16297281},
publisher = {MIT Press},
title = {{Evaluating the $\epsilon$-Domination Based Multi-Objective Evolutionary Algorithm for a Quick Computation of Pareto-Optimal Solutions}},
volume = {13},
year = {2005}
}
@article{Elhossini,
abstract = {This paper proposes an efficient particle swarm optimization (PSO) technique that can handle multi-objective optimization problems. It is based on the strength Pareto approach originally used in evolutionary algorithms (EA). The proposed modified particle swarm algorithm is used to build three hybrid EA-PSO algorithms to solve different multi-objective optimization problems. This algorithm and its hybrid forms are tested using seven benchmarks from the literature and the results are compared to the strength Pareto evolutionary algorithm (SPEA2) and a competitive multi-objective PSO using several metrics. The proposed algorithm shows a slower convergence, compared to the other algorithms, but requires less CPU time. Combining PSO and evolutionary algorithms leads to superior hybrid algorithms that outperform SPEA2, the competitive multi-objective PSO (MO-PSO), and the proposed strength Pareto PSO based on different metrics.},
author = {Elhossini, Ahmed and Areibi, Shawki and Dony, Robert},
doi = {10.1162/evco.2010.18.1.18105},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
keywords = { evolutionary algorithms, particle swarm optimization, strength Pareto evolutionary algorithm,Multi-objective optimization},
number = {1},
pages = {127--156},
pmid = {20064026},
publisher = {MIT Press},
title = {{Strength Pareto Particle Swarm Optimization and Hybrid EA-PSO for Multi-Objective Optimization}},
volume = {18},
year = {2010}
}
@inproceedings{kim2004spea2,
abstract = {Multi-objective optimization methods are essential to resolve real-world problems as most involve several types of objects. Several multi-objective genetic algorithms have been proposed. Among them, SPEA2 and NSGA-II are the most successful. In the present study, two new mechanisms were added to SPEA2 to improve its searching ability a more effective crossover mechanism and an archive mechanism to maintain diversity of the solutions in the objective and variable spaces. The new SPEA2 with these two mechanisms was named SPEA2+. To clarify the characteristics and effectiveness of the proposed method, SPEA2+ was applied to several test functions. In the comparison of SPEA2+ with SPEA2 and NSGA-II, SPEA2+ showed good results and the effects of the new mechanism were clarified. From these results, it was concluded that SPEA2+ is a good algorithm for multi-objective optimization problems.},
author = {Kim, Mifa and Hiroyasu, Tomoyuki and Miki, Mitsunori and Watanabe, Shinya},
doi = {10.1007/978-3-540-30217-9_75},
isbn = {3540230920},
issn = {03029743},
organization = {Springer},
pages = {742--751},
title = {{SPEA2+: Improving the Performance of the Strength Pareto Evolutionary Algorithm 2}},
volume = {3242/2004},
year = {2004}
}
@book{deb2001multi,
author = {Sbalzarini, I.F. and M{\"{u}}ller, S. and Koumoutsakos, Petros},
publisher = {John Wiley {\&} Sons},
title = {{Multiobjective optimization using evolutionary algorithms}},
volume = {2000},
year = {2000}
}
@article{Huang,
author = {Huang, V L and Suganthan, P N and Liang, J J},
doi = {10.1002/int.v21:2},
isbn = {0884-8173},
issn = {0884-8173},
journal = {International Journal Intelligence System},
number = {2},
pages = {209--226},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Comprehensive learning particle swarm optimizer for solving multiobjective optimization problems: Research Articles}},
volume = {21},
year = {2006}
}
@inproceedings{Deb06referencepoint,
author = {Deb, K and Sundar, J},
doi = {10.1145/1143997.1144112},
isbn = {1595931864},
issn = {0974-1259},
keywords = {moea},
pages = {635--642},
publisher = {Springer-Verlag},
title = {{Reference Point Based Multi-objective Optimization Using Evolutionary Algorithms}},
volume = {1},
year = {2006}
}
@inproceedings{4061431,
abstract = {Semantic QoS aware Web services incorporating the emerging Web services in the QoS aware system development are promoting service oriented software engineering (SOSE). To identify the steps toward semantic quality of service (QoS) aware Web services, this paper examines previous studies related to semantic QoS aware Web services, including QoS aware Web service architectures, QoS classification, QoS ontology, QoS specification languages, and Web service creation tools. Moreover, a case study is presented to discuss the gaps between our current quality driven software development approach and the semantic QoS aware Web services},
author = {Zhou, Jiehan and Niemel??, Eila},
doi = {10.1109/WI.2006.173},
isbn = {0769527477},
pages = {553--557},
title = {{Toward semantic QoS aware Web services: Issues, related studies and experience}},
year = {2007}
}
@inproceedings{916684,
abstract = {Internet service providers and infrastructural companies often employ mirrors of popular content to decrease client download time and server load. Due to the immense scale of the Internet and decentralized administration of the networks, companies have a limited number of sites (relative to the size of the Internet) where they can place mirrors. Mirrors of popular content are usually replicated on every site to maximize reachability to clients. We study the performance improvements as the number of mirrors increases under different placement algorithms subject to the constraint that mirrors can be placed only at certain locations. Although there are extensive theoretical studies on center placement and, analytical and empirical studies on Web cache placement, we are not aware of any published literature on mirror placement especially in the case of constrained mirror placement. Our results show that increasing the number of mirror sites under the constraint is effective in reducing client download time and reducing server load only for a surprisingly small range of values regardless of the mirror placement algorithm},
author = {Cronin, Eric and Jamin, Sugih and Jin, Cheng and Kurc, Anthony R. and Raz, Danny and Shavitt, Yuval},
doi = {10.1109/JSAC.2002.802066},
isbn = {0-7803-7016-3},
issn = {07338716},
keywords = {Constrained mirror placement,Internet experiments,Performance analysis,Placement algorithms},
number = {7},
pages = {1369--1382},
title = {{Constrained mirror placement on the Internet}},
volume = {20},
year = {2002}
}
@inproceedings{Vanrompay,
abstract = {Services running on mobile systems must be able to adapt themselves to changing user needs and availability of resources. We propose to use Genetic Algorithms to search for the best service variant in the current context. The chosen service composition is then deployed on a set of available nodes in an optimal way. We illustrate that Genetic Algorithms provide a scalable and self-organizing solution to service composition and deployment. We argue that the approach meets some main requirements demanded by services running on mobile systems. A motivating scenario is presented in which a distributed server allows users to share content and run applications in mobile ad-hoc networks.},
author = {Vanrompay, Yves and Rigole, Peter and Berbers, Yolande},
doi = {10.1145/1387309.1387313},
isbn = {9781605582085},
keywords = {genetic algorithms,service composition,service deployment},
pages = {13--18},
publisher = {ACM},
title = {{Genetic algorithm-based optimization of service composition and deployment}},
year = {2008}
}
@article{Kuriakose2005133,
author = {Kuriakose, Shajan and Shunmugam, M S},
doi = {10.1016/j.jmatprotec.2005.04.105},
issn = {0924-0136},
journal = {Journal of Materials Processing Technology},
keywords = {genetic algorithm,multi-objective optimization,pareto-optimal set,regression model,wire-edm},
number = {1–2},
pages = {133--141},
title = {{Multi-objective optimization of wire-electro discharge machining process by Non-Dominated Sorting Genetic Algorithm}},
volume = {170},
year = {2005}
}
@article{930314,
abstract = {Due to the flexibility in adapting to different fitness landscapes, self-adaptive evolutionary algorithms (SA-EAs) have been gaining popularity in the recent past. In this paper, we postulate the properties that SA-EA operators should have for successful applications in real-valued search spaces. Specifically, population mean and variance of a number of SA-EA operators such as various real-parameter crossover operators and self-adaptive evolution strategies are calculated for this purpose. Simulation results are shown to verify the theoretical calculations. The postulations and population variance calculations explain why self-adaptive genetic algorithms and evolution strategies have shown similar performance in the past and also suggest appropriate strategy parameter values, which must be chosen while applying and comparing different SA-EAs},
author = {Beyer, Hans Georg and Deb, Kalyanmoy},
doi = {10.1109/4235.930314},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Blend crossover operator,Evolution strategies,Fuzzy recombination operator,Genetic algorithms,Population mean,Population variance,Self-adaptation,Simulated binary crossover,Test fitness landscapes},
number = {3},
pages = {250--270},
title = {{On self-adaptive features in real-parameter evolutionary algorithms}},
volume = {5},
year = {2001}
}
@inproceedings{Raghuwanshi04,
abstract = {Evolutionary Algorithm (EA) possesses several characteristics that are desirable to solve real- world optimization problems up to a required level of satisfaction. Multiobjective Evolutionary Algorithms (MOEAs) are designed with regard to two common goals, fast and reliable convergence to the Pareto set and a good distribution of solutions along the front. Virtually each algorithm represents a unique combination of specific techniques to achieve these goals. Handling continuous search space with binary coded genetic algorithm has several difficulties. Real coded genetic algorithm represents parameters without coding, which makes representation of the solutions very close to the natural formulation of many problems. In real coded GA (RCGA) recombination and mutation operators are designed to work with real parameters. This survey gives state-ofthe-art of multiobjective evolutionary algorithms and real coded genetic algorithms.},
author = {Raghuwanshi, M M and Kakde, O G},
keywords = { genetic{\_}algorithm, multiobjective,candidacy},
pages = {150--161},
title = {{Survey on multiobjective evolutionary and real coded genetic algorithms}},
volume = {1984},
year = {2004}
}
@article{Sun,
abstract = {Recently, Web services have entered the competition for a new type of distributed e-commerce platform. This paper studies the placement of servers of a Web service intermediary. The intermediary serves as a common interface to its clients while obtaining Web services from independent providers. The intermediary locates its servers by minimizing costs where a major component is network latency. We propose and study an integer programming formulation to determine the locations and usage rates of the servers of an intermediary. A greedy heuristic method is used to obtain good solutions to the problem. ?? 2004 Elsevier B.V. All rights reserved.},
author = {Sun, Yi and Koehler, Gary J.},
doi = {10.1016/j.dss.2004.11.016},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Facility location,Heuristic algorithm,Network latency,Web services,Web services intermediary},
number = {1},
pages = {221--236},
publisher = {Elsevier Science Publishers B. V.},
title = {{A location model for a web service intermediary}},
volume = {42},
year = {2006}
}
@inproceedings{Xue,
author = {Xue, Bing and Zhang, Mengjie and Browne, Will N.},
doi = {10.1145/2330163.2330175},
isbn = {9781450311779},
keywords = {feature selection,multi-objective,particle swarm optimisation},
pages = {81},
publisher = {ACM},
title = {{Multi-objective particle swarm optimisation (PSO) for feature selection}},
year = {2012}
}
@inproceedings{1688438,
abstract = {We compare single-objective genetic algorithms (SOGAs) with multi-objective genetic algorithms (MOGAs) in their applications to multi-objective knapsack problems. First we discuss difficulties in comparing a single solution by SOGAs with a solution set by MOGAs. We also discuss difficulties in comparing several solutions from multiple runs of SOGAs with a large number of solutions from a single run of MOGAs. It is shown that existing performance measures are not necessarily suitable for such comparison. Then we compare SOGAs with MOGAs through computational experiments on multi-objective knapsack problems. Experimental results on two-objective problems show that MOGAs outperform SOGAs even when they are evaluated with respect to a scalar fitness function used in SOGAs. This is because MOGAs are more likely to escape from local optima. On the other hand, experimental results on four-objective problems show that the search ability of MOGAs is degraded by the increase in the number of objectives. Finally we suggest a framework of hybrid algorithms where a scalar fitness function in SOGAs is probabilistically used in MOGAs to improve the convergence of solutions to the Pareto front.},
author = {Ishibuchi, H. and Nojima, Y.},
doi = {10.1109/CEC.2006.1688438},
isbn = {0-7803-9487-9},
keywords = {Computational intelligence,Computer architecture,Computer science,Degradation,Evolutionary computation,Genetic algorithms,Hybrid power systems,Intelligent systems,Pareto optimization,knapsack problems,multi-objective genetic algorithms,multi-objective knapsack problems,scalar fitness function,single-objective genetic algorithms},
number = {1},
pages = {1143--1150},
title = {{Comparison between Single-Objective and Multi-Objective Genetic Algorithms: Performance Comparison and Performance Measures}},
year = {2006}
}
@article{lawler1963quadratic,
abstract = {This paper aims at describing the state of the art on quadratic assignment problems (QAPs). It discusses the most important developments in all aspects of the QAP such as linearizations, QAP polyhedra, algorithms to solve the problem to optimality, heuristics, polynomially solvable special cases, and asymptotic behavior. Moreover, it also considers problems related to the QAP, e.g. the biquadratic assignment problem, and discusses the relationship between the QAP and other well known combinatorial optimization problems, e.g. the traveling salesman problem, the graph partitioning problem, etc. The paper will appear in the Handbook of Combinatorial Optimization to be published by Kluwer Academic Publishers, P. Pardalos and D.-Z. Du, eds.},
author = {Burkard, Rainer E. and Cela, Eranda and Pardalos, Panos M. and Pitsoulis, Leonidas S.},
doi = {10.1007/BF01585868},
isbn = {978-1-4613-0303-9},
issn = {0025-5610},
journal = {Handbook of Combinatorial Optimization},
keywords = {68q25,90b80,90c27,algorithms,ams-classification,asymptotic behavior,polynomially solvable special cases,quadratic assignment problem},
number = {4},
pages = {1--71},
publisher = {INFORMS},
title = {{The Quadratic Assignment Problem}},
volume = {9},
year = {1998}
}
@article{man,
abstract = {This paper introduces genetic algorithms (GA) as a complete entity, in which knowledge of this emerging technology can be integrated together to form the framework of a design tool for industrial engineers. An attempt has also been made to explain “why'' and “when” GA should be used as an optimization tool.},
author = {Man, K. F. and Tang, K. S. and Kwong, S.},
doi = {10.1109/41.538609},
isbn = {0278-0046 VO - 43},
issn = {02780046},
journal = {IEEE Transactions on Industrial Electronics},
number = {5},
pages = {519--534},
publisher = {New York, NY: Institute of Electrical and Electronics Engineers, c1982-},
title = {{Genetic algorithms: Concepts and applications}},
volume = {43},
year = {1996}
}
@inproceedings{5961695,
abstract = {Popular Internet services are hosted by multiple geographically distributed data centers. The location of the data centers has a direct impact on the services' response times, capital and operational costs, and (indirect) carbon dioxide emissions. Selecting a location involves many important considerations, including its proximity to population centers, power plants, and network backbones, the source of the electricity in the region, the electricity, land, and water prices at the location, and the average temperatures at the location. As there can be many potential locations and many issues to consider for each of them, the selection process can be extremely involved and time-consuming. In this paper, we focus on the selection process and its automation. Specifically, we propose a framework that formalizes the process as a non-linear cost optimization problem, and approaches for solving the problem. Based on the framework, we characterize areas across the United States as potential locations for data centers, and delve deeper into seven interesting locations. Using the framework and our solution approaches, we illustrate the selection trade offs by quantifying the minimum cost of (1) achieving different response times, availability levels, and consistency times, and (2) restricting services to green energy and chiller-less data centers. Among other interesting results, we demonstrate that the intelligent placement of data centers can save millions of dollars under a variety of conditions. We also demonstrate that the selection process is most efficient and accurate when it uses a novel combination of linear programming and simulated annealing.},
author = {Goiri, {\'{I}}{\~{n}}igo and Le, Kien and Guitart, Jordi and Torres, Jordi and Bianchini, Ricardo},
doi = {10.1109/ICDCS.2011.19},
isbn = {9780769543642},
issn = {1063-6927},
keywords = {Internet;computer centres;linear programming;nonlinear programming;simulated annealing;Internet services;availability levels;capital costs;carbon dioxide emissions;chiller-less datacenters;consistency times;green energy;intelligent placement;linear programming;multiple geographically distributed data centers;network backbones;nonlinear cost optimization problem;operational costs;population centers;power plants;services response times;simulated annealing;water prices;Availability;Companies;Delay;Electricity;Optimization;Servers;Time factors},
pages = {131--142},
title = {{Intelligent placement of datacenters for internet services}},
year = {2011}
}
@inproceedings{Xie:2008:AMI:1389095.1389347,
author = {Xie, Huayang and Zhang, Mengjie and Andreae, Peter and Johnson, Mark},
doi = {doi:10.1145/1389095.1389347},
isbn = {9781605581309},
keywords = { genetic programming, modelling, multi-sampled Issue, simulation, tournament selection,genetic algorithms},
pages = {1323--1330},
publisher = {ACM},
title = {{An analysis of multi-sampled issue and no-replacement tournament selection}},
year = {2008}
}
@inproceedings{Morandat:2012:EDR:2367163.2367172,
author = {For, Functions and Analysis, Data},
pages = {104--131},
publisher = {Springer-Verlag},
title = {{Evaluating the Design of the R Language Objects and Functions For Data Analysis}},
year = {2012}
}
@article{6381531,
author = {Xue, Bing and Zhang, Mengjie and Member, Senior and Browne, Will N},
issn = {2168-2267},
journal = {IEEE transactions on cybernetics},
number = {6},
pages = {1656--1671},
title = {{Particle swarm optimization for feature selection in classification: a multi-objective approach}},
volume = {43},
year = {2013}
}
@inproceedings{He,
abstract = {An increasingly large fraction of Internet services are hosted on a cloud computing system such as Amazon EC2 or Windows Azure. But to date, no in-depth studies about cloud usage by Internet services has been performed. We provide a detailed measurement study to shed light on how modern web service deployments use the cloud and to identify ways in which cloud-using services might improve these deployments. Our results show that: 4{\%} of the Alexa top million use EC2/Azure; there exist several common deployment patterns for cloud-using web service front ends; and services can significantly improve their wide-area performance and failure tolerance by making better use of existing regional diversity in EC2. Driving these analyses are several new datasets, including one with over 34 million DNS records for Alexa websites and a packet capture from a large university network. Copyright 2013 ACM.},
author = {He, Keqiang and Fisher, Alexis and Wang, Liang and Gember, Aaron and Akella, Aditya and Ristenpart, Thomas},
doi = {10.1145/2504730.2504740},
isbn = {9781450319539},
keywords = {DNS,EC2,azure,cloud computing,trace analysis,web service},
pages = {177--190},
publisher = {ACM},
title = {{Next Stop, the Cloud: Understanding Modern Web Service Deployment in EC2 and Azure}},
volume = {10},
year = {2013}
}
@article{1304847,
abstract = {This paper presents an approach in which Pareto dominance is incorporated into particle swarm optimization (PSO) in order to allow this heuristic to handle problems with several objective functions. Unlike other current proposals to extend PSO to solve multiobjective optimization problems, our algorithm uses a secondary (i.e., external) repository of particles that is later used by other particles to guide their own flight. We also incorporate a special mutation operator that enriches the exploratory capabilities of our algorithm. The proposed approach is validated using several test functions and metrics taken from the standard literature on evolutionary multiobjective optimization. Results indicate that the approach is highly competitive and that can be considered a viable alternative to solve multiobjective optimization problems.},
author = {{Coello Coello}, Carlos A. and Pulido, Gregorio Toscano and Lechuga, Maximino Salazar},
doi = {10.1109/TEVC.2004.826067},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Pareto optimisation;evolutionary computation;Pareto dominance;constant handling mechanism;evolutionary multiobjective optimization;multiple objective handling;mutation operator;particle swarm optimization;Computer science;Constraint optimization;Data structures;Evolutionary computation;Genetic mutations;Particle swarm optimization;Proposals;Scholarships;Testing},
number = {3},
pages = {256--279},
pmid = {20371407},
title = {{Handling multiple objectives with particle swarm optimization}},
volume = {8},
year = {2004}
}
@incollection{NSPSO,
abstract = {This paper introduces a modified PSO, Non-dominated Sorting Particle Swarm Optimizer (NSPSO), for better multiobjective optimization. NSPSO extends the basic form of PSO by making a better use of particles' personal bests and offspring for more effective nondomination comparisons. Instead of a single comparison between a particle's personal best and its offspring, NSPSO compares all particles' personal bests and their offspring in the entire population. This proves to be effective in providing an appropriate selection pressure to propel the swarm population towards the Pareto-optimal front. By using the non-dominated sorting concept and two parameter-free niching methods, NSPSO and its variants have shown remarkable performance against a set of well-known difficult test functions (ZDT series). Our results and comparison with NSGA II show that NSPSO is highly competitive with existing evolutionary and PSO multiobjective algorithms.},
author = {Li, Xiaodong},
doi = {10.1007/3-540-45105-6_4},
isbn = {978-3-540-40602-0, 978-3-540-45105-1},
pages = {37--48},
publisher = {Springer Berlin Heidelberg},
title = {{A Non-dominated Sorting Particle Swarm Optimizer for Multiobjective Optimization}},
volume = {2723},
year = {2003}
}
@inproceedings{781913,
abstract = {Most popular evolutionary algorithms for multiobjective$\backslash$noptimisation maintain a population of solutions from which individuals$\backslash$nare selected for reproduction. In this paper, we introduce a simpler$\backslash$nevolution scheme for multiobjective problems, called the Pareto archived$\backslash$nevolution strategy (PAES). We argue that PAES may represent the simplest$\backslash$npossible non-trivial algorithm capable of generating diverse solutions$\backslash$nin the Pareto optimal set. The algorithm is identified as being a (1+1)$\backslash$nevolution strategy, using local search from a population of one but$\backslash$nusing a reference archive of previously found solutions in order to$\backslash$nidentify the approximate dominance ranking of the current and candidate$\backslash$nsolution vectors. PAES is intended as a good baseline approach, against$\backslash$nwhich more involved methods may be compared, and may also serve well in$\backslash$nsome real-world applications when local search seems superior to or$\backslash$ncompetitive with population-based methods. The performance of the new$\backslash$nalgorithm is compared with that of a MOEA based on the niched Pareto GA$\backslash$non a real world application from the telecommunications field. In$\backslash$naddition, we include results from experiments carried out on a suite of$\backslash$nfour test functions, to demonstrate the algorithm's general capability$\backslash$n},
author = {Knowles, Joshua and Corne, David},
doi = {10.1109/CEC.1999.781913},
isbn = {0-7803-5536-9},
issn = {1879-1026},
pages = {98--105},
pmid = {19520416},
title = {{The Pareto archived evolution strategy: A new baseline algorithm for Pareto multiobjective optimisation}},
volume = {1},
year = {1999}
}
@incollection{Micro,
author = {{Coello Coello Coello}, CarlosA. and {Toscano Pulido}, Gregorio},
isbn = {978-3-540-41745-3},
pages = {126--140},
publisher = {Springer Berlin Heidelberg},
title = {{A Micro-Genetic Algorithm for Multiobjective Optimization}},
volume = {1993},
year = {2001}
}
@inproceedings{Raquel,
abstract = {In this paper, we present an approach that extends the Particle Swarm Optimization (PSO) algorithm to handle multiobjective optimization problems by incorporating the mechanism of crowding distance computation into the algorithm of PSO, specifically on global best selection and in the deletion method of an external archive of nondominated solutions. The crowding distance mechanism together with a mutation operator maintains the diversity of nondominated solutions in the external archive. The performance of this approach is evaluated on test functions and metrics from literature. The results show that the proposed approach is highly competitive in converging towards the Pareto front and generates a well distributed set of nondominated solutions},
author = {Raquel, Carlo R. and Naval, Prospero C.},
doi = {10.1145/1068009.1068047},
isbn = {1595930108},
keywords = { multiobjective optimization, particle swarm optimization,crowding distance},
pages = {257},
publisher = {ACM},
title = {{An effective use of crowding distance in multiobjective particle swarm optimization}},
year = {2005}
}
@inproceedings{Dan:2008,
abstract = {Reuse of services in supporting new business processes, in addition to alignment of IT with business functions, is a key motivation in using Service-oriented Architecture (SOA) for developing business solutions. The three key benefits of service reuse ...},
author = {Dan, Asit and Johnson, Robert D. and Carrato, Tony},
doi = {10.1145/1370916.1370923},
isbn = {9781605580296},
issn = {02705257},
keywords = { service enhancement, service level agreement, service monitoring and management, service registry, service reuse, soa governance,business glossary},
number = {August},
pages = {25},
publisher = {ACM},
title = {{SOA service reuse by design}},
year = {2008}
}
@article{Papazoglou,
author = {Papazoglou, M P and Heuvel, W.J.V.D.},
issn = {1066-8888},
journal = {Vldb J.},
keywords = { Asynchronous and event-driven processing, Enterprise bus, Service oriented architecture, Web services,Application and service integration},
number = {3},
pages = {389--415},
publisher = {Springer-Verlag New York, Inc.},
title = {{Service oriented architectures: approaches, technologies and research issues}},
volume = {16},
year = {2007}
}
@article{Hwang11aninteger,
author = {Hwang, Junha and Kim, Sungyoung},
journal = {International Journal on Computer Science and Engineering},
keywords = {-maximal covering problem,integer programming,integer programming-based,local search},
number = {2},
pages = {837--843},
title = {{An Integer Programming-based Local Search for Large-scale Maximal Covering Problems}},
volume = {3},
year = {2011}
}
@inproceedings{488968,
abstract = {A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described},
author = {Wen, Jinghuan and Ma, Huimin and Zhang, Xiaoqin},
doi = {10.1109/ICNN.1995.488968},
isbn = {0-7803-2768-3},
issn = {10070214},
keywords = {death process,occlusion interference,particle swarm optimization,statistical fitness function,virtual tracking},
number = {2},
pages = {221--230},
pmid = {21368999},
title = {{Optimization of the occlusion strategy in visual tracking}},
volume = {21},
year = {2016}
}
@incollection{nsga2_cri,
abstract = {NSGA-II is one of the most popular algorithms for solving$\backslash$nMulti-objective Optimization Problems. It has been used to solve$\backslash$ndifferent real-world optimization problems; however, NSGA-II has been$\backslash$ncriticized for its high computational cost and bad performance on$\backslash$napplications with more than two objective functions. In this paper, we$\backslash$npropose a high-performance architecture for the NSGA-II using parallel$\backslash$ncomputing, for evaluation functions and genetic operators. In the$\backslash$nproposed architecture, the Mishra Fast Algorithm for finding the Non$\backslash$nDominated Set was used. In this paper, we propose a modification in the$\backslash$nsorting process for the NSGA-II that improves the distribution of the$\backslash$nsolutions in the Pareto front. Results for five different test functions$\backslash$nusing distinct crossover and mutation operators to test performance are$\backslash$npresented.},
author = {Dom??nguez, Josu?? and Montiel-Ross, Oscar and Sep??lveda, Roberto},
doi = {10.1007/978-3-642-35323-9-13},
isbn = {9783642353222},
issn = {14349922},
keywords = {Genetic algorithm,Multi-objective optimization,NSGA - II,Pareto Optimal},
pages = {321--341},
publisher = {Springer},
title = {{High-performance architecture for the modified NSGA-II}},
volume = {294},
year = {2013}
}
@misc{Zitzler99evolutionaryalgorithms,
abstract = {Ether some techniques are in general superior to others, which algorithms are suited to which kind of problem, and what the specific advantages and drawbacks of certain methods are. The subject of this work is the comparison and the improvement of existing multiobjective evolutionary algorithms and their application to system design problems in computer engineering. In detail, the major contributions are: An experimental methodology to compare multiobjective optimizers is devel- oped. In particular, quantitative measures to assess the quality of trade-off fronts are introduced and a set of general test problems is defined, which are i) easy to formulate, ii) represent essential aspects of real-world problems, and iii) test for different types of problem difficulty. On the basis of this methodology, an extensive comparison of numerous evolu- tionary techniques is performed in which further aspects such as the influence of elitism and the population size are also investigated. A novel approach to multiobjective optimization, the strength Pareto evolution- ary algorithm, is proposed. It combines both established and new techniques in a unique manner. Two complex multicriteria applications are addressed using evolutionary algo- rithms: i) the automatic synthesis of heterogeneous hardware/systems and ii) the multidimensional exploration of software implementations for digital signal processors.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Zitzler, Eckart},
doi = {citeulike-article-id:4597043},
eprint = {9605103},
isbn = {3826568311},
issn = {10769757},
number = {30},
pmid = {17255001},
primaryClass = {cs},
title = {{Evolutionary Algorithms for Multiobjective Optimization : Methods and Applications}},
volume = {no13398},
year = {1999}
}
@inproceedings{Phan8,
abstract = {As Internet data centers (IDCs) have been increasing in scale and complexity, they are currently a significant source of energy consumption and CO 2 emission. This paper proposes and evaluates a new framework to operate a federation of IDCs in a "green" way. The proposed framework, called Green Monster, dynamically moves services (i.e., workload) across IDCs for increasing renewable energy consumption while maintaining their performance. It makes decisions of service migration and placement with an evolutionary multi-objective optimization algorithm (EMOA) that evolves a set of solution candidates through global and local search processes. The proposed EMOA seeks the Pareto-optimal solutions by balancing the trade-offs among conicting optimization objectives such as renewable energy consumption, cooling energy consumption and response time performance. Copyright 2012 ACM.},
author = {Phan, Dung H. and Suzuki, Junichi and Carroll, Raymond and Balasubramaniam, Sasitharan and Donnelly, William and Botvich, Dmitri},
doi = {10.1145/2330784.2330788},
isbn = {9781450311786},
keywords = {cloud comput-,evolutionary multiobjective optimization,ing,internet data centers,renewable energy,sustainability},
pages = {19--27},
publisher = {ACM},
title = {{Evolutionary multiobjective optimization for green clouds}},
year = {2012}
}
@inproceedings{6557869,
abstract = {In this paper, we deal with cloud brokering for the assignment optimization of VM requests in three-tier cloud infrastructures. We investigate the Pareto-based meta-heuristic approach to take into account multiple client and broker-centric optimization criteria. We propose a new multi-objective Genetic Algorithm (MOGA-CB) that can be integrated in a cloud broker. Two objectives are considered in the optimization process: minimizing both the response time and the cost of the selected VM instances to satisfy the clients and to maximize the profit of the broker. The approach has been experimented using realistic data of different types of Amazon EC2 instances and their pricing history. The reported results show that MOGA-CB provides efficiently effective Pareto sets of solutions.},
author = {Kessaci, Yacine and Melab, Nouredine and Talbi, El Ghazali},
doi = {10.1109/CEC.2013.6557869},
isbn = {9781479904549},
keywords = {VM instances,VM requests,client satisfaction,cloud brokering,cloud computing,genetic algorithm,multi-objective optimization,scheduling},
pages = {2496--2503},
title = {{A pareto-based genetic algorithm for optimized assignment of VM requests on a cloud brokering environment}},
year = {2013}
}
@article{knowles2000,
abstract = {We introduce a simple evolution scheme for multiobjective optimization problems, called the Pareto Archived Evolution Strategy (PAES). We argue that PAES may represent the simplest possible nontrivial algorithm capable of generating diverse solutions in the Pareto optimal set. The algorithm, in its simplest form, is a (1 + 1) evolution strategy employing local search but using a reference archive of previously found solutions in order to identify the approximate dominance ranking of the current and candidate solution vectors. (1 + 1)-PAES is intended to be a baseline approach against which more involved methods may be compared. It may also serve well in some real-world applications when local search seems superior to or competitive with population-based methods. We introduce (1 + lambda) and (mu + lambda) variants of PAES as extensions to the basic algorithm. Six variants of PAES are compared to variants of the Niched Pareto Genetic Algorithm and the Nondominated Sorting Genetic Algorithm over a diverse suite of six test functions. Results are analyzed and presented using techniques that reduce the attainment surfaces generated from several optimization runs into a set of univariate distributions. This allows standard statistical analysis to be carried out for comparative purposes. Our results provide strong evidence that PAES performs consistently well on a range of multiobjective optimization tasks.},
author = {Knowles, Joshua D. and Corne, David W.},
doi = {10.1162/106365600568167},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
number = {2},
pages = {149--172},
pmid = {10843519},
publisher = {MIT Press},
title = {{Approximating the Nondominated Front Using the Pareto Archived Evolution Strategy}},
volume = {8},
year = {2000}
}
@article{kemps2012dynamic,
author = {Kemps-Snijders, Marc and Brouwer, Matthijs and {Pieter Kunst}, Jan and Visser, Tom},
journal = {Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012)},
title = {{Dynamic web service deployment in a cloud environment}},
year = {2012}
}
@phdthesis{Sun:2003:,
annote = {AAI3120151},
author = {Sun, Yi},
publisher = {University of Florida},
title = {{A Location Model for Web Services Intermediaries}},
year = {2003}
}
@article{Huang:2013:,
abstract = {Services are an indispensable component in cloud computing. Web services are particularly important. As an increasing number of Web services provides equivalent functions, one common issue faced by users is the selection of the most appropriate one based on quality. This article presents a conceptual framework that characterizes the quality of Web services, an algorithm that quantifies them, and a system architecture that ranks Web services by using the proposed algorithm. In particular, the algorithm, called UsageQoS that computes the scores of quality of service (QoS) of Web services within a community, makes use of the usage frequencies of Web services. The frequencies are defined as the numbers of times invoked by other services in a given time period. The UsageQoS algorithm is able to optionally take user ratings as its initial input. The proposed approach has been validated by extensively experimenting on several datasets, including two real datasets. The results of the experiments have demonstrated that our approach is capable of estimating QoS parameters of Web services, regardless of whether user ratings are available or not. {\textcopyright} 2013 ACM.},
author = {Huang, Xiaodi},
doi = {10.1145/2532635},
issn = {15591131},
journal = {ACM Transactions on the Web (TWEB)},
keywords = { Web services, online social network, propagation,QoS},
number = {1},
pages = {1},
publisher = {ACM},
title = {{UsageQoS: Estimating the QoS of Web services through online user communities}},
volume = {8},
year = {2013}
}
@inproceedings{1004478,
abstract = {The investigation of the performance of the particle swarm optimization (PSO) method in integer programming problems, is the main theme of the present paper. Three variants of PSO are compared with the widely used branch and bound technique, on several integer programming test problems. Results indicate that PSO handles efficiently such problems, and in most cases it outperforms the branch and bound technique},
author = {Laskari, E.C. and Parsopoulos, K.E. and Vrahatis, M.N.},
doi = {10.1109/CEC.2002.1004478},
isbn = {0-7803-7282-4},
keywords = {evolutionary computation;integer programming;optimisation;branch and bound technique;integer programming;particle swarm optimization;Artificial intelligence;Combinatorial mathematics;Graph theory;Linear programming;Logic;Neural networks;Particle swarm optimization;Production;Productivity;Testing},
pages = {1582--1587},
title = {{Particle swarm optimization for integer programming}},
volume = {2},
year = {2002}
}
@article{4120263,
abstract = {Antenna design variables, such as size, have contin- uous values while others, such as permittivity, have a finite number of values. Having both variable types in one problem requires a mixed integer optimization algorithm. This paper describes a ge- netic algorithm (GA) that works with real and/or binary values in the same chromosome. The algorithm is demonstrated on de- signing low side-lobe phase tapers, circularly polarized patch an- tennas, and identically thinned subarrays.},
author = {Haupt, RL},
doi = {10.1109/TAP.2007.891510},
journal = {Antennas and Propagation, IEEE Transactions on},
number = {3},
pages = {577--582},
title = {{Antenna design with a mixed integer genetic algorithm}},
volume = {55},
year = {2007}
}
@article{liu2013discrete,
author = {Liu, Dong and Feng, Quanyuan and Wang, Wei-Bo},
doi = {10.2528/PIER12080804},
issn = {1559-8985},
journal = {Progress In Electromagnetics Research},
number = {November 2012},
pages = {407--424},
publisher = {EMW Publishing},
title = {{Discrete Optimization Problems of Linear Array Synthesis By Using Real Number Particle Swarm Optimization}},
volume = {133},
year = {2013}
}
@article{Anghinolfi200973,
author = {Anghinolfi, D and Paolucci, M},
doi = {10.1016/j.ejor.2007.10.044},
issn = {03772217},
journal = {European Journal of Operational Research},
number = {1},
pages = {pages 73----85},
title = {{A new discrete particle swarm optimization approach for the single-machine total weighted tardiness scheduling problem with sequence-dependent setup times}},
volume = {193},
year = {2009}
}
@inproceedings{Auger:2009,
abstract = {The hypervolume indicator is a set measure used in evolutionary multiobjective optimization to evaluate the performance of search algorithms and to guide the search. Multiobjective evolutionary algorithms using the hypervolume indicator transform multiobjective problems into single objective ones by searching for a finite set of solutions maximizing the corresponding hypervolume indicator. In this paper, we theoretically investigate how those  optimal {\&}{\#}956;--distributions -finite sets of {\&}{\#}956; solutions maximizing the hypervolume indicator-are spread over the Pareto front of biobjective problems. This problem is of high importance for practical applications as these sets characterize the preferences that the hypervolume indicator encodes, i.e., which types of Pareto set approximations are favored.},
author = {Auger, Anne and Bader, Johannes},
doi = {10.1145/1527125.1527138},
isbn = {9781605584140},
keywords = {hypervolume indicator,multiobjective optimization},
pages = {87--102},
publisher = {ACM},
title = {{Theory of the Hypervolume Indicator : Optimal $\mu$ -Distributions and the Choice of the Reference Point}},
year = {2009}
}
@article{coello2002theoretical,
author = {Coello, Carlos A Coello},
journal = {Comput. Methods Appl. Mech. Engrg},
number = {11},
pages = {1245--1287},
publisher = {North-Holland},
title = {{Theoretical and numerical constraint-handling techniques used with evolutionary algorithms: a survey of the state of the art}},
volume = {191},
year = {2002}
}
@techreport{veldhuizen99,
abstract = {This research organizes, presents, and analyzes contemporary Multiobjective Evolutionary Algorithm (MOEA) research and associated Multiobjective Optimization Problems (MOPs). Using a consistent MOEA terminology and notation, each cited MOEAs' key factors are presented in tabular form for ease of MOEA identification and selection. A detailed quantitative and qualitative MOEA analysis is presented, providing a basis for conclusions about various MOEA-related issues. The traditional notion of building blocks is extended to the MOP domain in an effort to develop more effective and efficient MOEAs. Additionally, the MOEA community's limited test suites contain various functions whose origins and rationale for use are often unknown. Thus, using general test suite guidelines appropriate MOEA test function suites are substantiated and generated. An experimental methodology incorporating a solution database and appropriate metrics is offered as a proposed evaluation framework allowing absolute comparisons of specific MOEA approaches. Taken together, this document's classifications, analyses, and new innovations present a complete, contemporary view of current MOEA "state of the art" and possible future research. Researchers with basic EA knowledge may also use part of it as a largely self-contained introduction to MOEAs.},
author = {{Van Veldhuizen}, David a.},
doi = {10.1109/TE.1962.4322266},
institution = {Evolutionary Computation},
isbn = {0-599-28316-5},
issn = {0893-7141},
title = {{Multiobjective Evolutionary Algorithms: Classifications, Analyses and New Innovations}},
year = {1999}
}
@inproceedings{870296,
author = {{Van Veldhuizen}, David Allen and Lamont, G B},
doi = {10.1109/CEC.2000.870296},
isbn = {0780363752},
keywords = {MOEA performance comparison,evolutionary algorithms,evolutionary computation,multiobjective EA,multiobjective evolutionary algorithm performance,optimization problems},
pages = {204--211 vol.1},
title = {{On measuring multiobjective evolutionary algorithm performance}},
volume = {1},
year = {2000}
}
@inproceedings{1501598,
abstract = { In this paper, we propose a new mechanism to maintain diversity in multi-objective optimization problems. The proposed mechanism is based on the use of stripes that are applied on objective function space and that is independent of the search engine adopted to solve the multi-objective optimization problem. In order to validate the proposed approach, we included it in a multi-objective particle swarm optimizer. Our approach was compared with respect to two multi-objective evolutionary algorithms, which are representative of the state-of-the-art in the area. The results obtained indicate that our proposed mechanism is a viable alternative to maintain diversity in the context of multi-objective optimization.},
author = {Villalobos-Arias, Mario Alberto and Pulido, Gregorio Toscano and {Coello Coello}, Carlos A.},
doi = {10.1109/SIS.2005.1501598},
isbn = {0780389166},
pages = {23--30},
title = {{A proposal to use stripes to maintain diversity in a multi-objective particle swarm optimizer}},
volume = {2005},
year = {2005}
}
@inproceedings{export:141114,
abstract = {In this paper, we propose virtual data center (VDC) as the unit of resource allocation for multiple tenants in the cloud. VDCs are more desirable than physical data centers because the resources allocated to VDCs can be rapidly adjusted as tenants' needs change. To enable the VDC abstraction, we design a data center network virtualization architecture called SecondNet. SecondNet achieves scalability by distributing all the virtual-to-physical mapping, routing, and bandwidth reservation state in server hypervisors. Its port-switching based source routing (PSSR) further makes SecondNet applicable to arbitrary network topologies using commodity servers and switches. SecondNet introduces a centralized VDC allocation algorithm for bandwidth guaranteed virtual to physical mapping. Simulations demonstrate that our VDC allocation achieves high network utilization and low time complexity. Our implementation and experiments show that we can build SecondNet on top of various network topologies, and SecondNet provides bandwidth guarantee and elasticity, as designed.},
author = {Guo, Chuanxiong and Lu, Guohan and Wang, Helen J H.J. and Yang, Shuang and Kong, Chao and Sun, Peng and Wu, Wenfei and Zhang, Yongguang},
doi = {http://doi.acm.org/10.1145/1921168.1921188},
isbn = {978-1-4503-0448-1},
issn = {01464833},
keywords = {and,bandwidth guarantee,dcn,kong,microsoft research asia,peng,this work was performed,virtual data center,wenfei were interns at,when shuang},
number = {Vdc},
pages = {15:1----15:12},
publisher = {Association for Computing Machinery, Inc.},
title = {{SecondNet: a data center network virtualization architecture with bandwidth guarantees}},
year = {2010}
}
@inproceedings{export:149565,
abstract = {The shared nature of the network in today's multi-tenant datacenters implies that network performance for tenants can vary significantly. This applies to both production datacenters and cloud environments. Network performance variability hurts application},
author = {Ballani, Hitesh and Costa, Paolo and Karagiannis, Thomas and Rowstron, Ant},
doi = {10.1145/2018436.2018465},
isbn = {9781450307970},
issn = {01464833},
pages = {242},
publisher = {ACM SIGCOMM},
title = {{Towards predictable datacenter networks}},
year = {2011}
}
@inproceedings{6217521,
abstract = {Given Cloud Computing geographical distribution on multiple regions, the location of data centers, servers and software components and the way information is routed are fundamental issues in system performance. This article presents the Cloud Location and Routing Problem (CLRP), a mathematical problem aiming at solving all those issues in a multi-layer and integrated fashion through a convex integer programming formulation. The results underline the importance of location and routing when offering content to the whole Internet in an efficient way, showing that the budget and the number of data centers opened have a critical impact in overall network performance. {\textcopyright} 2012 IEEE.},
author = {Larumbe, F and Sans{\`{o}}, B},
doi = {10.1109/CCGrid.2012.124},
isbn = {9780769546919},
keywords = {Cloud computing; Grid computing; Integer programm,Convex integer programming; Data centers; Facility,Location},
pages = {841--844},
title = {{Optimal location of data centers and software components in cloud computing network design}},
year = {2012}
}
@inproceedings{Verbancsics,
abstract = {An important goal for the generative and developmental systems (GDS) community is to show that GDS approaches can compete with more mainstream approaches in machine learning (ML). One popular ML domain is RoboCup and its subtasks (e.g. Keepaway). This paper shows how a GDS approach called HyperNEAT competes with the best results to date in Keepaway. Furthermore, a significant advantage of GDS is shown to be in transfer learning. For example, playing Keepaway should contribute to learning the full game of soccer. Previous approaches to transfer have focused on transforming the original representation to fit the new task. In contrast, this paper explores transfer with a representation designed to be the same even across different tasks. A bird's eye view (BEV) representation is introduced that can represent different tasks on the same two-dimensional map. Yet the problem is that a raw two-dimensional map is high-dimensional and unstructured. The problem is addressed naturally by indirect encoding, which compresses the representation in HyperNEAT by exploiting its geometry. The result is that the BEV learns a Keepaway policy that transfers from two different training domains without further learning or manipulation. The results in this paper thus show the power of GDS versus other ML methods. Copyright 2010 ACM.},
author = {Verbancsics, Phillip and Stanley, Kenneth O.},
doi = {10.1145/1830483.1830587},
isbn = {9781450300728},
number = {Gecco},
pages = {547},
publisher = {ACM},
title = {{Transfer learning through indirect encoding}},
volume = {2010},
year = {2010}
}
@book{olivas,
author = {Olivas, E S},
isbn = {9781605667676},
pages = {242--264},
publisher = {IGI Global},
title = {{Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques: Algorithms, Methods, and Techniques}},
year = {2009}
}
@article{man1996genetic,
abstract = {This paper introduces genetic algorithms (GA) as a complete entity, in which knowledge of this emerging technology can be integrated together to form the framework of a design tool for industrial engineers. An attempt has also been made to explain “why'' and “when” GA should be used as an optimization tool.},
author = {Man, K. F. and Tang, K. S. and Kwong, S.},
doi = {10.1109/41.538609},
isbn = {0278-0046 VO - 43},
issn = {02780046},
journal = {IEEE Transactions on Industrial Electronics},
number = {5},
pages = {519--534},
publisher = {New York, NY: Institute of Electrical and Electronics Engineers, c1982-},
title = {{Genetic algorithms: Concepts and applications}},
volume = {43},
year = {1996}
}
@inproceedings{de1992genetic,
author = {{De Jong}, K.A.},
pages = {3--14},
title = {{Are Genetic Algorithms Functions Optimizers?}},
volume = {2},
year = {1992}
}
@article{de1993genetic,
abstract = {Genetic Algorithms (GAs) have received a great deal of attention regarding their potential as optimization techniques for complex functions. The level of interest and success in this area has led to a number of improvements to GA-based function optimizers and a good deal of progress in characterizing the kinds of functions that are easy/hard for GAs to optimize. With all this activity, there has been a natural tendency to equate GAs with function optimization. However, the motivating context of Holland's initial GA work was the design and implementation of robust adaptive systems. In this paper we argue that a proper understanding of GAs in this broader adaptive systems context is a necessary prerequisite for understanding their potential application to any problem domain. We then use these insights to better understand the strengths and limitations of GAs as function optimizers.},
author = {De{\~{}}Jong, K a},
doi = {10.1016/B978-0-08-094832-4.50006-4},
isbn = {1558602631},
issn = {10816593},
journal = {Proceedings of the Second Workshop on Foundations of Genetic Algorithms},
pages = {5--18},
title = {{Genetic Algorithms are NOT Function Optimizers}},
volume = {2},
year = {1992}
}
@book{rechenberg1971,
abstract = {170 S. mit 36 Abb. Frommann-Holzboog-Verlag. Stuttgart . Broschiert},
author = {Rechenberg, Ingo},
doi = {10.1002/fedr.19750860506},
isbn = {978-3772803734},
issn = {00148962},
number = {5},
pages = {337--337},
title = {{Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution}},
volume = {86},
year = {1971}
}
@book{schwefel1975,
author = {Schwefel, H.-P.},
keywords = {neurofitter},
pages = {1--370},
publisher = {Technische Universit{\"{a}}t Berlin},
title = {{Evolutionsstrategie und numerische Optimierung}},
year = {1975}
}
@inproceedings{hassan2005,
author = {Hassan, R and Cohanim, B and de Weck, O},
pages = {1--13},
title = {{A Comparison of Particle Swarm Optimization and the Genetic Algorithm}},
year = {2005}
}
@inproceedings{godinez2010,
abstract = {The optimization of multi objective problems is currently an area of important research and development. The importance of type of problems has allowed the development of multiple metaheuristics for their solution. To determine which multi objective metaheuristic has the best performance with respect to a problem, in this article an experimental comparison between two of them: Sorting Genetic Algorithm No dominated-II (NSGA-II) and Multi Objective Particle Swarm Optimization (MOPS) using ZDT test functions is made. The results obtained by both algorithms are compared and analyzed based on different performance metrics that evaluate both the dispersion of the solutions on the Pareto front, and its proximity to it.},
author = {God??nez, Adriana Cort??s and Espinosa, Luis Ernesto Mancilla and Montes, Efr??n Mezura},
doi = {10.1109/CERMA.2010.13},
isbn = {9780769542041},
keywords = {Comparative study,Multiobjective optimization,NSGA-II,OMOPSO},
organization = {IEEE},
pages = {28--33},
title = {{An experimental comparison of multiobjective algorithms: NSGA-II and OMOPSO}},
year = {2010}
}
@book{bougue,
abstract = {Web services and Service-Oriented Computing (SOC) have become thriving areas of academic research, joint university/industry research projects, and novel IT products on the market. SOC is the computing paradigm that uses Web services as building blocks for the engineering of composite, distributed applications out of the reusable application logic encapsulated by Web services. Web services could be considered the best-known and most standardized technology in use today for distributed computing over the Internet. Web Services Foundations is the first installment of a two-book collection covering the state-of-the-art of both theoretical and practical aspects of Web services and SOC research. This book specifically focuses on the foundations of Web services and SOC and covers - among others - Web service composition, non-functional aspects of Web services, Web service selection and recommendation, and assisted Web service composition. The editors collect advanced topics in the second book of the collection, Advanced Web Services, (Springer, 2013). Both books together comprise approximately 1400 pages and are the result of an enormous community effort that involved more than 100 authors, comprising the world's leading experts in this field. **},
author = {Pautasso, Cesare},
doi = {10.1007/978-1-4614-7518-7},
isbn = {978-1-4614-7517-0},
pages = {31--51},
publisher = {Springer},
title = {{Web Services Foundations}},
year = {2014}
}
@inproceedings{5598294,
abstract = {The notion of Cloud computing has not only reshaped the field of distributed systems but also fundamentally changed how businesses utilize computing today. While Cloud computing provides many advanced features, it still has some shortcomings such as the relatively high operating cost for both public and private Clouds. The area of Green computing is also becoming increasingly important in a world with limited energy resources and an ever-rising demand for more computational power. In this paper a new framework is presented that provides efficient green enhancements within a scalable Cloud computing architecture. Using power-aware scheduling techniques, variable resource management, live migration, and a minimal virtual machine design, overall system efficiency will be vastly improved in a data center based Cloud with minimal performance overhead.},
author = {a.J. Younge and Laszewski, G. Von and Wang, Lizhe Wang Lizhe and Lopez-Alarcon, S. and Carithers, W.},
doi = {10.1109/GREENCOMP.2010.5598294},
isbn = {978-1-4244-7612-1},
issn = {14770520},
keywords = {Cloud Computing,Green Computing,Scheduling,Virtualization},
pages = {357--364},
title = {{Efficient resource management for Cloud computing environments}},
year = {2010}
}
@inproceedings{Schien,
author = {Schien, Daniel and Shabajee, Paul and Wood, Stephen G and Preist, Chris},
doi = {10.1145/2488388.2488485},
isbn = {9781450320351},
keywords = {carbon footprinting,digital media,green software,sustainability},
pages = {1111--1121},
publisher = {International World Wide Web Conferences Steering Committee},
title = {{A Model for Green Design of Online News Media Services}},
year = {2013}
}
@book{abraham2005evolutionary,
abstract = {This paper presents a very short introduction to multiobjective evolutionary al- gorithms, including their basic concepts and their main components. The dis- cussion focuses on algorthmic design and, therefore, the issues discussed include selectionmechanisms, diversitymaintenance mechanisms, and elitism in a multi- objective context.},
author = {Coello, Carlos A. Coello},
doi = {10.1002/widm.43},
issn = {19424787},
number = {5},
pages = {444--447},
publisher = {Springer},
title = {{Evolutionary multiobjective optimization}},
volume = {1},
year = {2011}
}
@article{coello2006evolutionary,
author = {Coello, C A},
journal = {Computational Intelligence Magazine, IEEE},
number = {1},
pages = {28--36},
publisher = {IEEE},
title = {{Evolutionary multi-objective optimization: a historical view of the field}},
volume = {1},
year = {2006}
}
@article{coello1998two,
abstract = {In this paper, we introduce two new multiobjective optimization techniques based on the genetic algorithm (GA), and implemented as part of a multiobjective optimization tool called MOSES (Multiobjective Optimization of Systems in the Engineering Sciences). These methods are based in the concept of min-max optimum, and can produce the Pareto set and the best trade-off among the objectives. The results produced by these approaches are compared to those produced with other mathematical programming techniques and GA-based approaches using two engineering design problems, showing the new techniques' capability to generate better trade-offs than the approaches previously reported in the literature.},
author = {Coello, C A C and Christiansen, A D},
doi = {Doi 10.1080/02630259808970240},
isbn = {1028-6608},
issn = {1028-6608},
journal = {Civil Engineering and Environmental Systems},
keywords = {artificial intelligence,design optimization,genetic algorithms,minmax optimization,multicriteria optimization,multiobjective optimization,parameters,structural design,vector optimization},
number = {3},
pages = {207--243},
publisher = {Taylor {\&} Francis},
title = {{Two new GA-based methods for multiobjective optimization}},
volume = {15},
year = {1998}
}
@article{goldberg1988genetic,
author = {Goldberg, David E. and Holland, John H.},
doi = {10.1023/A:1022602019183},
issn = {1573-0565},
journal = {Machine Learning},
number = {2-3},
pages = {95--99},
publisher = {Springer},
title = {{Genetic Algorithms and Machine Learning}},
volume = {3},
year = {1989}
}
@article{Kritikos,
abstract = {Quality of service (QoS) can be a critical element for achieving the business goals of a service provider, for the acceptance of a service by the user, or for guaranteeing service characteristics in a composition of services, where a service is defined as either a software or a software-support (i.e., infrastructural) service which is available on any type of network or electronic channel. The goal of this article is to compare the approaches to QoS description in the literature, where several models and metamodels are included. consider a large spectrum of models and metamodels to describe service quality, ranging from ontological approaches to define qualitymeasures, metrics, and dimensions, to metamodels enabling the specification of quality-based service requirements and capabilities as well as of SLAs (Service-Level Agreements) and SLA templates for service provisioning. Our survey is performed by inspecting the characteristics of the available approaches to reveal which are the consolidated ones and which are the ones specific to given aspects and to analyze where the need for further research and investigation lies. The approaches here illustrated have been selected based on a systematic review of conference proceedings and journals spanning various research areas in computer science and engineering, including: distributed, information, and telecommunication systems, networks and security, and service-oriented and grid computing.},
address = {New York, NY, USA},
author = {et al Kritikos, Kyriakos},
doi = {10.1145/2522968.2522969},
isbn = {978-1-4503-4805-8},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {jul},
number = {1},
pages = {44},
publisher = {ACM},
title = {{A Survey on Service Quality Description}},
volume = {46},
year = {2013}
}
@article{Anisetti,
abstract = {The Service-Oriented Architecture (SOA) paradigm is giving rise to a new generation of applications built by dynamically composing loosely coupled autonomous services. Clients (i.e., software agents acting on behalf of human users or service providers) implementing such complex applications typically search and integrate services on the basis of their functional requirements and of their trust in the service suppliers. A major issue in this scenario relates to the definition of an assurance technique allowing clients to select services on the basis of their nonfunctional requirements and increasing their confidence that the selected services will satisfy such requirements. In this article, we first present an assurance solution that focuses on security and supports a test-based security certification scheme for Web services. The certification scheme is driven by the security properties to be certified and relies upon a formal definition of the service model. The evidence supporting a certified property is computed using a model-based testing approach that, starting from the service model, automatically generates the test cases to be used in the service certification. We also define a set of indexes and metrics that evaluate the assurance level and the quality of the certification process. Finally, we present our evaluation toolkit and experimental results obtained applying our certification solution to a financial service implementing the Interactive Financial eXchange (IFX) standard.},
address = {New York, NY, USA},
author = {Anisetti, Marco and Ardagna, Claudio A. and Damiani, Ernesto and Saonara, Francesco},
doi = {10.1145/2460383.2460384},
isbn = {1559-1131},
issn = {15591131},
journal = {ACM Transactions on the Web},
keywords = {Model-based testing,security certification,service-oriented architecture,symbolic transition systems,web services},
month = {may},
number = {2},
pages = {1--41},
publisher = {ACM},
title = {{A test-based security certification scheme for web services}},
volume = {7},
year = {2013}
}
@article{Flach,
abstract = {To serve users quickly, Web service providers build infrastruc- ture closer to clients and use multi-stage transport connections. Although these changes reduce client-perceived round-trip times, TCP's current mechanisms fundamentally limit latency improve- ments. We performed a measurement study of a largeWeb service provider and found that, while connections with no loss complete close to the ideal latency of one round-trip time, TCP's timeout- driven recovery causes transfers with loss to take five times longer on average. In this paper, we present the design of novel loss recovery mech- anisms for TCP that judiciously use redundant transmissions to minimize timeout-driven recovery. Proactive, Reactive, and Cor- rective are three qualitatively-different, easily-deployable mecha- nisms that (1) proactively recover from losses, (2) recover from them as quickly as possible, and (3) reconstruct packets to mask loss. Crucially, the mechanisms are compatible both with mid- dleboxes and with TCP's existing congestion control and loss re- covery. Our large-scale experiments on Google's production net- work that serves billions of flows demonstrate a 23{\%} decrease in the mean and 47{\%} in 99th percentile latency over today's TCP. Categories},
author = {Flach, Tobias and Dukkipati, Nandita and Terzis, Andreas and Raghavan, Barath and Cardwell, Neal},
doi = {10.1145/2486001.2486014},
isbn = {9781450320566},
issn = {0146-4833},
journal = {Acm Sigcomm},
keywords = {congestion control,internet measurements,packet loss,recovery,redundancy,tcp,web latency},
month = {aug},
number = {4},
pages = {159--170},
publisher = {ACM},
title = {{Reducing Web Latency: the Virtue of Gentle Aggression}},
volume = {43},
year = {2013}
}
@article{cha2008design,
abstract = {By introducing Web Services, distributed GIS(Geospatial Information System) services from different vendors can be dynamically integrated into a GIS application using the interoperable standard SOAP(Simple Object Access Protocol). However, it is debatable whether SOAP can really meet the performance requirement of GIS. Additionally, GIS Web Services' performance may be improved by using asynchronous technique. Ajax, one of the technologies of "Web 2.0". Integrating Ajax(Asynchronous JavaScript and XML) approach into GIS visualization Web Services have performance enhancement, because it provides more interactive user experience. This paper presents an experimental evaluation of the performance of different SOAP variants: standard SOAP, SwA/MIME, and SOAP/MTOM. SOAP/MTOM is proved to be the fastest and the most efficient messaging protocol. For sintegrating Ajax approach, compare performance of models between Web Services and Web Services using Ajax. This comparison results that Web Services using Ajax represent good performance in images fetching and user roundtrip time because it fetches required images beforehand.},
author = {Cha, Seung Jun and Hwang, Yun Young and Chang, Yoon Seop and Kim, Kyung Ok and Lee, Kyu Chul},
issn = {19750080},
journal = {International Journal of Multimedia and Ubiquitous Engineering},
number = {1},
pages = {27--44},
title = {{Design and evaluation of experiment methods for improving performance in GIS web services}},
volume = {3},
year = {2008}
}
@article{klotz2013practical,
author = {Klotz, Ed and Newman, Alexandra M and Tyson, Mike},
journal = {Surveys in Operations Research and Management Science},
keywords = {cuts,heuristics,memory use,mixed integer linear programming,run time,tight formulations,tutorials},
number = {1},
pages = {18--32},
publisher = {Elsevier},
title = {{Practical Guidelines for Solving Difficult Mixed Integer Linear Programs}},
volume = {18},
year = {2012}
}
@article{zhang2008multi,
author = {Zhang, W and Liu, Y},
journal = {International Journal of Electrical Power {\&} Energy {\ldots}},
number = {9},
pages = {525--532},
publisher = {Elsevier},
title = {{Multi-objective reactive power and voltage control based on fuzzy optimization strategy and fuzzy adaptive particle swarm}},
volume = {30},
year = {2008}
}
@article{4633340,
abstract = {Partly due to lack of test problems, the impact of the Pareto set (PS) shapes on the performance of evolutionary algorithms has not yet attracted much attention. This paper introduces a general class of continuous multiobjective optimization test instances with arbitrary prescribed PS shapes, which could be used for studying the ability of multiobjective evolutionary algorithms for dealing with complicated PS shapes. It also proposes a new version of MOEA/D based on differential evolution (DE), i.e., MOEA/D-DE, and compares the proposed algorithm with NSGA-II with the same reproduction operators on the test instances introduced in this paper. The experimental results indicate that MOEA/D could significantly outperform NSGA-II on these test instances. It suggests that decomposition based multiobjective evolutionary algorithms are very promising in dealing with complicated PS shapes. {\textcopyright} 2008 IEEE.},
author = {Li, Hui and Zhang, Qingfu},
doi = {10.1109/TEVC.2008.925798},
isbn = {1941-0026
1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Aggregation,Decomposition,Differential evolution,Evolutionary algorithms,Multiobjective optimization,Pareto optimality,Test problems},
month = {apr},
number = {2},
pages = {284--302},
title = {{Multiobjective optimization problems with complicated pareto sets, MOEA/ D and NSGA-II}},
volume = {13},
year = {2009}
}
@inproceedings{khanesar2007novel,
abstract = {Particle swarm optimization (PSO) as a novel computational intelligence technique, has succeeded in many continuous problems. But in discrete or binary version there are still some difficulties. In this paper a novel binary PSO is proposed. This algorithm proposes a new definition for the velocity vector of binary PSO. It will be shown that this algorithm is a better interpretation of continuous PSO into discrete PSO than the older versions. Also a number of benchmark optimization problems are solved using this concept and quite satisfactory results are obtained.},
author = {{Mojtaba Ahmadieh Khanesar, Mohammad Teshnehlab}, Mahdi Aliyari Shoorehdeli and Khanesar, Mojtaba Ahmadieh and Teshnehlab, Mohammad and Shoorehdeli, Mahdi Aliyari},
doi = {10.1109/MED.2007.4433821},
isbn = {978-1-4244-1281-5},
issn = {142441282X},
keywords = {Binary particle swarm optimization,Computational intelligence,Discrete optimization,binary particle swarm optimization,computational intelligence,discrete,optimization},
number = {1},
organization = {IEEE},
pages = {1--6},
title = {{A novel binary particle swarm optimization}},
volume = {1},
year = {2007}
}
@article{xue2013particle,
author = {Xue, Bing and Zhang, Mengjie and Member, Senior and Browne, Will N},
issn = {2168-2267},
journal = {IEEE transactions on cybernetics},
number = {6},
pages = {1656--1671},
publisher = {IEEE},
title = {{Particle swarm optimization for feature selection in classification: a multi-objective approach}},
volume = {43},
year = {2013}
}
@online{Alexa,
author = {Alexa},
month = {apr},
title = {{Alexa - Actionable Analytics for the Web}},
url = {http://www.alexa.com/},
year = {2016}
}
@inproceedings{xin2009particle,
abstract = {The inertia weight is often used to control the global exploration and local exploitation abilities of particle swarm optimizers (PSO). In this paper, a group of strategies with multi-stage linearly-decreasing inertia weight (MLDW) is proposed in order to get better balance between the global and local search. Six most commonly used benchmarks are used to evaluate the MLDW strategies on the performance of PSOs. The results suggest that the PSO with W5 strategy is a good choice for solving unimodal problems due to its fast convergence speed, and the CLPSO with W5 strategy is more suitable for solving multimodal problems. Also, W5-CLPSO can be used as a robust algorithm because it is not sensitive to the complexity of problems for solving.},
author = {Xin, Jianbin and Chen, Guimin and Hai, Yubao},
doi = {10.1109/CSO.2009.420},
isbn = {9780769536057},
organization = {IEEE},
pages = {505--508},
title = {{A particle swarm optimizer with multi-stage linearly-decreasing inertia weight}},
volume = {1},
year = {2009}
}
@article{qi1994theoretical,
author = {Qi, Xiaofeng and Palmieri, F},
doi = {10.1109/72.265965},
issn = {1045-9227},
journal = {Trans. Neur. Netw.},
number = {1},
pages = {102--119},
publisher = {IEEE},
title = {{Theoretical Analysis of Evolutionary Algorithms with an Infinite Population Size in Continuous Space. Part I: Basic Properties of Selection and Mutation}},
volume = {5},
year = {1994}
}
@inproceedings{halfaoui2015qos,
author = {Halfaoui, Amal and Hadjila, Fethallah and Didi, Fedoua},
organization = {Springer},
pages = {291--300},
title = {{QoS-Aware Web Services Selection Based on Fuzzy Dominance}},
year = {2015}
}
@inproceedings{alrifai2010selecting,
abstract = {Web service composition enables seamless and dynamic integration of business applications on the web. The performance of the composed application is determined by the performance of the involved web services. Therefore, non-functional, quality of service ...},
author = {Alrifai, Mohammad and Skoutas, Dimitrios and Risse, Thomas},
doi = {10.1145/1772690.1772693},
isbn = {9781605587998},
keywords = {optimization,qos,service composition,web services},
number = {5},
organization = {ACM},
pages = {11--20},
title = {{Selecting skyline services for QoS-based web service composition}},
volume = {2588},
year = {2010}
}
@misc{ML,
annote = {Accessed: 2017-4-10},
author = {Geethika, By Bhavya},
howpublished = {$\backslash$url{\{}http://www.kdnuggets.com/2017/02/machine-learning-data-science-apis-updated.html{\}}},
title = {{50 Useful Machine Learning {\&} Prediction APIs}},
year = {2015}
}
@inproceedings{yusoh2012composite,
abstract = {Software as a Service (SaaS) is gaining more and more attention from software users and providers recently. This has raised many new challenges to SaaS providers in providing better SaaSes that suit everyone needs at minimum costs. One of the emerging approaches in tackling this challenge is by delivering the SaaS as a composite SaaS. Delivering it in such an approach has a number of benefits, including flexible offering of the SaaS functions and decreased cost of subscription for users. However, this approach also introduces new problems for SaaS resource management in a Cloud data centre. We present the problem of composite SaaS resource management in Cloud data centre, specifically on its initial placement and resource optimization problems aiming at improving the SaaS performance based on its execution time as well as minimizing the resource usage. Our approach differs from existing literature because it addresses the problems resulting from composite SaaS characteristics, where we focus on the SaaS requirements, constraints and interdependencies. The problems are tackled using evolutionary algorithms. Experimental results demonstrate the efficiency and the scalability of the proposed algorithms.},
author = {Yusoh, Zeratul Izzah Mohd and Tang, Maolin},
doi = {10.1109/CLOUD.2012.61},
isbn = {978-1-4673-2892-0},
issn = {2159-6182},
keywords = {Cloud computing,Evolutionary Algorithm,Genetic algorithms,Optimization,Placement,Resource management,Servers,Software as a Service,Virtual machining,cloud computing,cloud data centre,composite SaaS placement,computer centres,evolutionary algorithms,evolutionary computation,resource management,resource optimization,software users},
organization = {IEEE},
pages = {590--597},
title = {{Composite SaaS Placement and Resource Optimization in Cloud Computing Using Evolutionary Algorithms}},
year = {2012}
}
@article{de2016dynamic,
abstract = {Cloud systems are becoming attractive for many companies. Rather than over-provisioning the privately owned infrastructure for peak demands, some of the work can be overspilled to external infrastructure to meet deadlines. In this paper, we investigate how to dynamically and automatically provision resources on the private and external clouds such that the number of workloads meeting their deadline is maximized. We specifically focus on jobs consisting of multiple interdependent tasks with a priori an unknown structure and even adaptable at runtime. The proposed approach is model-driven: knowledge on the job structure on the one hand; and resource needs and scaling behavior on the other hand. Information is built up based on monitoring information and simulated 'what-if'-scenarios. Using this dynamically constructed job resource model, the resources needed by each job in order to meet its deadline is derived. Different algorithms are evaluated on how the required resources and jobs are scheduled over time on the available infrastructure. The evaluation is carried out using synthetic workloads.},
author = {{De Coninck}, Elias and Verbelen, Tim and Vankeirsbilck, Bert and Bohez, Steven and Simoens, Pieter and Dhoedt, Bart},
doi = {10.1016/j.jss.2016.05.011},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Cloud computing,Deadline constrained workflow scheduling,Dynamic resource allocation},
pages = {101--114},
publisher = {Elsevier},
title = {{Dynamic auto-scaling and scheduling of deadline constrained service workloads on IaaS clouds}},
volume = {118},
year = {2016}
}
@inproceedings{yusoh2012composite,
abstract = {Software as a Service (SaaS) is gaining more and more attention from software users and providers recently. This has raised many new challenges to SaaS providers in providing better SaaSes that suit everyone needs at minimum costs. One of the emerging approaches in tackling this challenge is by delivering the SaaS as a composite SaaS. Delivering it in such an approach has a number of benefits, including flexible offering of the SaaS functions and decreased cost of subscription for users. However, this approach also introduces new problems for SaaS resource management in a Cloud data centre. We present the problem of composite SaaS resource management in Cloud data centre, specifically on its initial placement and resource optimization problems aiming at improving the SaaS performance based on its execution time as well as minimizing the resource usage. Our approach differs from existing literature because it addresses the problems resulting from composite SaaS characteristics, where we focus on the SaaS requirements, constraints and interdependencies. The problems are tackled using evolutionary algorithms. Experimental results demonstrate the efficiency and the scalability of the proposed algorithms.},
author = {Yusoh, Zeratul Izzah Mohd and Tang, Maolin},
doi = {10.1109/CLOUD.2012.61},
isbn = {978-1-4673-2892-0},
issn = {2159-6182},
keywords = {Cloud computing,Evolutionary Algorithm,Genetic algorithms,Optimization,Placement,Resource management,Servers,Software as a Service,Virtual machining,cloud computing,cloud data centre,composite SaaS placement,computer centres,evolutionary algorithms,evolutionary computation,resource management,resource optimization,software users},
organization = {IEEE},
pages = {590--597},
title = {{Composite SaaS Placement and Resource Optimization in Cloud Computing Using Evolutionary Algorithms}},
year = {2012}
}
@article{Vidyarthi201420,
author = {Vidyarthi, Navneet and Jayaswal, Sachin},
doi = {10.1016/j.cor.2014.02.014},
issn = {0305-0548},
journal = {Computers and Operation Research},
keywords = {Congestion,Constraint generation method,Location–allocation,Queueing,Service system design,Stochastic demand},
pages = {20--30},
title = {{Efficient solution of a class of location – allocation problems with stochastic demand and congestion}},
volume = {48},
year = {2014}
}
@inproceedings{5961695,
abstract = {Popular Internet services are hosted by multiple geographically distributed data centers. The location of the data centers has a direct impact on the services' response times, capital and operational costs, and (indirect) carbon dioxide emissions. Selecting a location involves many important considerations, including its proximity to population centers, power plants, and network backbones, the source of the electricity in the region, the electricity, land, and water prices at the location, and the average temperatures at the location. As there can be many potential locations and many issues to consider for each of them, the selection process can be extremely involved and time-consuming. In this paper, we focus on the selection process and its automation. Specifically, we propose a framework that formalizes the process as a non-linear cost optimization problem, and approaches for solving the problem. Based on the framework, we characterize areas across the United States as potential locations for data centers, and delve deeper into seven interesting locations. Using the framework and our solution approaches, we illustrate the selection trade offs by quantifying the minimum cost of (1) achieving different response times, availability levels, and consistency times, and (2) restricting services to green energy and chiller-less data centers. Among other interesting results, we demonstrate that the intelligent placement of data centers can save millions of dollars under a variety of conditions. We also demonstrate that the selection process is most efficient and accurate when it uses a novel combination of linear programming and simulated annealing.},
author = {Goiri, {\'{I}}{\~{n}}igo and Le, Kien and Guitart, Jordi and Torres, Jordi and Bianchini, Ricardo},
doi = {10.1109/ICDCS.2011.19},
isbn = {9780769543642},
issn = {1063-6927},
keywords = {Internet;computer centres;linear programming;nonlinear programming;simulated annealing;Internet services;availability levels;capital costs;carbon dioxide emissions;chiller-less datacenters;consistency times;green energy;intelligent placement;linear programming;multiple geographically distributed data centers;network backbones;nonlinear cost optimization problem;operational costs;population centers;power plants;services response times;simulated annealing;water prices;Availability;Companies;Delay;Electricity;Optimization;Servers;Time factors},
month = {jun},
pages = {131--142},
title = {{Intelligent placement of datacenters for internet services}},
year = {2011}
}
@article{TorrentFontbona20134593,
abstract = {Immobile Location-Allocation (ILA) is a combinatorial problem which consists in, given a set of facilities and a set of demand points, determining the optimal service each facility has to offer and allocating the demand to such facilities. The applicability of optimization methods is tied up to the dimensionality of the problem, but since the distance between data points is a key factor, clustering techniques to partition the data space can be applied, converting the large initial problem into several simpler ILA problems that can be solved separately. This paper presents a novel method that combines clustering and heuristic methods to solve an ILA problem, which reduces the elapsed time keeping the quality of the solution found compared with other heuristics methods. ?? 2013 Elsevier Ltd. All rights reserved.},
author = {Torrent-Fontbona, F. and Muñoz, V. and López, B.},
doi = {10.1016/j.eswa.2013.01.065},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Affinity propagation,Clustering,Heuristics,Immobile location-Allocation,Simulated annealing},
number = {11},
pages = {4593--4599},
title = {{Solving large immobile location-Allocation by affinity propagation and simulated annealing. Application to select which sporting event to watch}},
volume = {40},
year = {2013}
}
@article{pasandideh2012genetic,
abstract = {In many service and industrial applications of the facility location problem, the number of required facilities along with allocation of the customers to the facilities are the two major questions that need to be answered. In this paper, a facility location problem with stochastic customer demand and immobile servers is studied. Two objectives considered in this problem are: (1) minimizing the average customer waiting time and (2) minimizing the average facility idletime percentage. We formulate this problem using queuing theory and solve the model by a genetic algorithm within the desirability function framework. Several examples are presented to demonstrate the applications of the proposed methodology. {\textcopyright} Springer Science+Business Media, LLC 2010.},
author = {Pasandideh, Seyed Hamid Reza and Niaki, Seyed Taghi Akhavan},
doi = {10.1007/s10845-010-0416-1},
issn = {09565515},
journal = {Journal of Intelligent Manufacturing},
keywords = {Desirability function,Facility location,Genetic algorithm,Queuing theory},
number = {3},
pages = {651--659},
publisher = {Springer},
title = {{Genetic application in a facility location problem with random demand within queuing framework}},
volume = {23},
year = {2012}
}
@article{lin2014solving,
abstract = {Logistic systems with uncertain demand, travel time, and on-site processing time are studied here where sequential trip travel is allowed. The relationship between three levels of decisions: facility location, demand allocation, and resource capacity (number of service units), satisfying the response time requirement, is analysed. The problem is formulated as a stochastic mixed integer program. A simulation-based hybrid heuristic is developed to solve the dynamic problem under different response time service level. An initial solution is obtained from solving static location-allocation models, followed by iterative improvement of the three levels of decisions by ejection, reinsertion procedure with memory of feasible and infeasible service regions. Results indicate that a higher response time service level could be achieved by allocating a given resource under an appropriate decentralized policy. Given a response time requirement, the general trend is that the minimum total capacity initially decreases with more facilities. During this stage, variability in travel time has more impact on capacity than variability in demand arrivals. Thereafter, the total capacity remains stable and then gradually increases. When service level requirement is high, the dynamic dispatch based on first-come-first-serve rule requires smaller capacity than the one by nearest-neighbour rule.},
author = {Lin, Carrie Ka Yuk C.K.Y.},
doi = {10.1155/2014/492340},
issn = {1024-123X},
journal = {Mathematical Problems in Engineering},
pages = {1--25},
publisher = {Hindawi Publishing Corporation},
title = {{Solving a Location, Allocation, and Capacity Planning Problem with Dynamic Demand and Response Time Service Level}},
volume = {2014},
year = {2014}
}
@article{Menasce:2002:QIW:613357.613758,
abstract = { Quality of service (QoS) is a combination of several qualities or properties of a service, such as: availability is the percentage of time that a service is operating; security properties include the existence and type of authentication mechanisms the service offers, confidentiality and data integrity of messages exchanged, nonrepudiation of requests or messages, and resilience to denial-of-service attacks; response time is the time a service takes to respond to various types of requests; Response time is a function of load intensity, which can be measured in terms of arrival rates (such as requests per second) or number of concurrent requests. QoS takes into account not only the average response time, but also the percentile of the response time; and throughput is the rate at which a service can process requests. QoS measures can include the maximum throughput or a function that describes how throughput varies with load intensity. The QoS measure is observed by Web services users. These users are not human beings but programs that send requests for services to Web service providers. QoS issues in Web services have to be evaluated from the perspective of the providers of Web services and from the perspective of the users of these services.},
address = {Piscataway, NJ, USA},
author = {Menasc{\'{e}}, Daniel A.},
doi = {10.1109/MIC.2002.1067740},
isbn = {1089-7801},
issn = {10897801},
journal = {IEEE Internet Computing},
month = {nov},
number = {6},
pages = {72--75},
publisher = {IEEE Educational Activities Department},
title = {{QoS issues in web services}},
volume = {6},
year = {2002}
}

@article{Holland:1962fy,
abstract = {The purpose of this paper is to outline a theory of automata appropriate to the properties, requirements and questions of adaptation. The conditions that such a theory should satisfy come from not one but several fields: It should be possible to formulate, at least in an abstract version, some of the key hypotheses and problems from relevant parts of biology, particularly the areas concerned with molecular control and neurophysiology. The work in theoretical genetics initiated by R. A. Fisher 5 and Sewall Wright 24 should find a natural place in the theory. At the same time the rigorous methods of automata theory should be brought to bear (particularly those parts concerned with growing automata 1, 2, 3, 7, 8, 12, 15, 18, 23). Finally the theory should include among its models abstract counterparts of artificial adaptive systems currently being studied, systems such as Newell-Shaw-Simon's "General Problem Solver" 13, Selfridge's "Pandemonium" 17, von Neumann's self-reproducing automata 22 and Turing's morphogenetic systems 19, 20.},
author = {Holland, John H.},
doi = {10.1145/321127.321128},
isbn = {978-3-642-19156-5 978-3-642-19157-2},
issn = {00045411},
journal = {Journal of the ACM},
number = {3},
pages = {297--314},
title = {{Outline for a Logical Theory of Adaptive Systems}},
volume = {9},
year = {1962}
}
@article{nsgaii,
abstract = {Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN3) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN2) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed},
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T.},
doi = {10.1109/4235.996017},
isbn = {1089-778X VO - 6},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Constraint handling,Elitism,Genetic algorithms,Multicriterion decision making,Multiobjective optimization,Pareto-optimal solutions},
month = {apr},
number = {2},
pages = {182--197},
title = {{A fast and elitist multiobjective genetic algorithm: NSGA-II}},
volume = {6},
year = {2002}
}
@inproceedings{Service_dataset,
abstract = {With the increasing popularity of cloud computing as a solution for building high-quality applications on distributed components, efficiently evaluating user-side quality of cloud components becomes an urgent and crucial research problem. However, invoking all the available cloud components from user-side for evaluation purpose is expensive and impractical. To address this critical challenge, we propose a neighborhood-based approach, called CloudPred, for collaborative and personalized quality prediction of cloud components. CloudPred is enhanced by feature modeling on both users and components. Our approach CloudPred requires no additional invocation of cloud components on behalf of the cloud application designers. The extensive experimental results show that CloudPred achieves higher QoS prediction accuracy than other competing methods. We also publicly release our large-scale QoS dataset for future related research in cloud computing.},
author = {Zhang, Yilei and Zheng, Zibin and Lyu, Michael R.},
doi = {10.1109/SRDS.2011.10},
isbn = {9780769544502},
issn = {10609857},
keywords = {Cloud Computing,Prediction,QoS},
pages = {1--10},
title = {{Exploring latent features for memory-based QoS prediction in cloud computing}},
year = {2011}
}
@article{Guzek:2015ds,
abstract = {Cloud computing is significantly reshaping the computing industry. Individuals and small organizations can benefit from using state-of-the-art services and infrastructure, while large companies are attracted by the flexibility and the speed with which they can obtain the services. Service providers compete to offer the most attractive conditions at the lowest prices. However, the environmental impact and legal aspects of cloud solutions pose additional challenges. Indeed, the new cloud-related techniques for resource virtualization and sharing and the corresponding service level agreements call for new optimization models and solutions. It is important for computational intelligence researchers to understand the novelties introduced by cloud computing. The current survey highlights and classifies key research questions, the current state of the art, and open problems.},
archivePrefix = {arXiv},
arxivId = {1209.5467},
author = {Guzek, Mateusz and Bouvry, Pascal and Talbi, El Ghazali},
doi = {10.1109/MCI.2015.2405351},
eprint = {1209.5467},
isbn = {0957-4174},
issn = {1556603X},
journal = {IEEE Computational Intelligence Magazine},
number = {2},
pages = {53--67},
pmid = {1000102567},
title = {{A survey of evolutionary computation for resource management of processing in cloud computing [review article]}},
volume = {10},
year = {2015}
}
@article{Energy_9,
abstract = {In this paper we study the problem of energy-aware resource allocation for hosting long-term services or on-demand computing jobs in clusters, e.g., deployed as part of computing infrastructures. We formalize the problem as three constrained optimization problems: maximize job performance under power consumption constraints, minimize power consumption under job performance constraints, and optimize a linear combination of power consumption and job performance. These problems are NP-hard but, given an instance, a bound on the optimal solution can be computed via a rational linear program. We propose polynomial heuristics for all three problems. Simulation experiments show that in all three cases some heuristics can achieve results close to optimal, i.e., lead to good job performance while conserving energy. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Borgetto, Damien and Casanova, Henri and {Da Costa}, Georges and Pierson, Jean Marc},
doi = {10.1016/j.future.2011.04.018},
isbn = {0167-739X},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Allocation,Energy-aware,Heuristic,Optimal,Service},
number = {5},
pages = {769--779},
title = {{Energy-aware service allocation}},
volume = {28},
year = {2012}
}
@book{Fogel:1962wv,
author = {Fogel, Lawrence Jerome},
number = {2},
pages = {14--19},
publisher = {Industrial research},
title = {{Autonomous Automata}},
volume = {4},
year = {1962}
}
@article{ope,
abstract = {Electrical discharge machining (EDM) is a process for shaping hard metals and forming deep and complex shaped holes by arc erosion in all types of electro conductive materials. In the present work, the effectiveness of the EDM process with tungsten carbide and cobalt composites is evaluated in terms of the material removal rate and the surface finish quality of the workpiece produced. The objective of this research is to study the influence of operating parameters of EDM such as pulse current, pulse on time, electrode rotation and flushing pressure on material removal rate and surface roughness. The experimental results are used to develop the statistical models based on second order polynomial equations for the different process characteristics. The non-dominated sorting genetic algorithm (NSGA-II) has been used to optimize the processing conditions. A non-dominated solution set has been obtained and reported.},
author = {Kanagarajan, D. and Karthikeyan, R. and Palanikumar, K. and Davim, J. Paulo},
doi = {10.1007/s00170-006-0921-8},
isbn = {0017000609218},
issn = {02683768},
journal = {International Journal of Advanced Manufacturing Technology},
keywords = {Electrical discharge machining (EDM),Modeling,Non-dominated sorting genetic algorithm (NSGA-II),WC/Co composite},
number = {11-12},
pages = {1124--1132},
title = {{Optimization of electrical discharge machining characteristics of WC/Co composites using non-dominated sorting genetic algorithm (NSGA-II)}},
volume = {36},
year = {2008}
}
@article{Klockgether:1970tw,
author = {Klockgether, J and Schwefel, H P},
journal = {Proc. 11th Symp. Engineering Aspects of Magnetohydrodynamics},
number = {DECEMBER 1969},
pages = {141--148},
title = {{Two-phase nozzle and hollow core jet experiments}},
year = {1970}
}

@incollection{kennedy2011particle,
abstract = {This is the first book devoted entirely to Particle Swarm Optimization (PSO), which is a non-specific algorithm, similar to evolutionary algorithms, such as taboo search and ant colonies.Since its original development in 1995, PSO has mainly been applied to continuous-discrete heterogeneous strongly non-linear numerical optimization and it is thus used almost everywhere in the world. Its convergence rate also makes it a preferred tool in dynamic optimization.},
author = {Clerc, Maurice},
doi = {10.1002/9780470612163},
isbn = {9780470612163},
mendeley-groups = {TSC},
pages = {760--766},
pmid = {14208342},
publisher = {Springer},
title = {{Particle Swarm Optimization}},
year = {2006}
}


@inproceedings{Kennedy:1997hd,
abstract = {The particle swarm algorithm adjusts the trajectories of a$\backslash$npopulation of {\&}ldquo;particles{\&}rdquo; through a problem space on the$\backslash$nbasis of information about each particle's previous best performance and$\backslash$nthe best previous performance of its neighbors. Previous versions of the$\backslash$nparticle swarm have operated in continuous space, where trajectories are$\backslash$ndefined as changes in position on some number of dimensions. The paper$\backslash$nreports a reworking of the algorithm to operate on discrete binary$\backslash$nvariables. In the binary version, trajectories are changes in the$\backslash$nprobability that a coordinate will take on a zero or one value.$\backslash$nExamples, applications, and issues are discussed},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Kennedy, J. and Eberhart, R.C.},
doi = {10.1109/ICSMC.1997.637339},
eprint = {arXiv:1011.1669v3},
isbn = {0-7803-4053-1},
issn = {1062-922X},
pages = {4--8},
pmid = {20646090},
publisher = {IEEE},
title = {{A discrete binary version of the particle swarm algorithm}},
volume = {5},
year = {1997}
}
@article{Back:1997gb,
abstract = {Evolutionary computation has started to receive significant attention during the last decade, although the origins can be traced back to the late 1950's. This article surveys the history as well as the current state of this rapidly growing field. We describe the purpose, the general structure, and the working principles of different approaches, including genetic algorithms (GA) (with links to genetic programming (GP) and classifier systems (CS)), evolution strategies (ES), and evolutionary programming (EP) by analysis and comparison of their most important constituents (i.e. representations, variation operators, reproduction, and selection mechanism). Finally, we give a brief overview on the manifold of application domains, although this necessarily must remain incomplete},
author = {Back, T. and Hammel, U. and Schwefel, H.-P.},
doi = {10.1109/4235.585888},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {PHD,classi er,evolution strategies,evolution-,evolutionary computation,evolutionary program-,genetic algorithms,genetic programming,his rst issue of,ming,octobre,systems,the ieee transactions on},
number = {1},
pages = {3--17},
title = {{Evolutionary computation: comments on the history and current state}},
volume = {1},
year = {1997}
}
@book{Tan2016,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2016. In recent years, Web services technology is becoming increasingly popular because of the convenience, low cost and capacity to be composed into high-level business processes. The service location-allocation problem for a Web service provider is critical and urgent, because some factors such as network latency can make serious effect on the quality of service (QoS). This paper presents a multi-objective optimization algorithm based on NSGA-II to solve the service location-allocation problem. A stimulated experiment is conducted using the WS-DREAM dataset. The results are compared with a single objective genetic algorithm (GA). It shows NSGA-II based algorithm can provide a set of best solutions that outperforms genetic algorithm.},
author = {Tan, Boxiong and Ma, Hui and Zhang, Mengjie},
doi = {10.1007/978-3-319-28270-1_21},
isbn = {9783319282695},
issn = {16113349},
pages = {246--257},
title = {{Optimization of Location Allocation of Web Services Using a Modified Non-dominated Sorting Genetic Algorithm}},
volume = {9592},
year = {2016}
}
@book{Tan2016a,
abstract = {{\textcopyright} Springer International Publishing Switzerland 2016. Web service location allocation problem is an important problem in the modern IT industry. In this paper, the two major objectives, i.e. deployment cost and network latency, are considered simultaneously. In order to solve this new multi-objective problem effectively, we adopted the framework of binary Particle Swarm Optimization (PSO) due to its efficacy that has been demonstrated in many optimization problems. Specifically, we developed two PSO variants, one with weighted-sum fitness function (WSPSO) and the other with dominancebased fitness function. Concretely, it uses the fast Non-dominate Sorting scheme, and thus is called NSPSO. The experimental results showed that both PSO variants performed better than NSGA-II, which is the one of the most commonly used multi-objective genetic algorithms. Furthermore, we have found that NSPSO achieved a more diverse set of solutions than WSPSO, and thus covers the Pareto front better. This demonstrates the efficacy of using the dominance-based fitness function in solving multi-objective Web service location allocation problem.},
author = {Tan, Boxiong and Mei, Yi and Ma, Hui and Zhang, Mengjie},
doi = {10.1007/978-3-319-30698-8_15},
isbn = {9783319306971},
issn = {16113349},
keywords = {Combinatorial optimization,Particle swarm optimization,Web service location allocation},
pages = {219--234},
title = {{Particle swarm optimization for multi-objective web service location allocation}},
volume = {9595},
year = {2016}
}
