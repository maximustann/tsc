\documentclass[10pt,journal,compsoc]{IEEEtran}

\usepackage{graphicx,amsmath,amsfonts,amstext,float,mathtools,hyperref,multicol,array,amssymb}
%\usepackage[ruled,vlined]{algorithm2e}

\usepackage{algorithm, algpseudocode}
%\usepackage{psfig)
\usepackage{soul}

%\usepackage{kbordermatrix}

%\usepackage[para,online,flushleft]{threeparttable}
\usepackage{subcaption}
\usepackage{flushend}
%\usepackage{float}
%\usepackage{epsfig}
%\usepackage{subfigure}
%\newfloat{fig}{thp}{lof}[chapter]
\floatname{fig}{Figure}

\let\bbordermatrix\bordermatrix
%\patchcmd{\bbordermatrix}{8.75}{4.75}{}{}
%\patchcmd{\bbordermatrix}{\left(}{\left[}{}{}
%\patchcmd{\bbordermatrix}{\right)}{\right]}{}{}

%\usepackage{float}

\newtheorem{example}{Example}
\newtheorem{definition}{Definition}


%\usepackage{flushend}
\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi
\ifCLASSINFOpdf
\else
\fi

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Evolutionary Multi-Objective Optimization for Web Service Location Allocation}


\author{Boxiong~Tan,
        Hui~Ma,
        Yi~Mei,
        and~Mengjie~Zhang
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem School of Engineering and Computer Science, Victoria University of Wellington,
PO Box 600, Wellington 6140, New Zealand.\protect\\
E-mail: \{boxiong.tan, hui.ma, yi.mei, mengjie.zhang\}@ecs.vuw.ac.nz}
\thanks{Manuscript received x x, x; revised x x, x.}}

% The paper headers
\markboth{IEEE Transactions on Services Computing, ~Vol.~\textless XX\textgreater, No.~\textless 000\textgreater, \textless Month\textgreater~2017}%
{da Silva \MakeLowercase{\textit{et al.}}: Evolutionary Multi-Objective Optimization for Web Service Location Allocation}



\IEEEtitleabstractindextext{
\begin{abstract}
With the ever increasing number of functionally similar web services being available on the Internet, the market competition is becoming intense. Web service providers (WSPs) realize that good Quality of Service (QoS) is a key of business success and low network latency is a critical measurement of good QoS. Because network latency is related to geometric location, a straightforward way to reduce network latency is to allocate services to proper locations. However, Web Service Location Allocation (WSLA) problem is a challenging task since there are multiple objectives potentially conflict with each other and the solution search space has a combinatorial nature. In this paper, we consider minimizing the network latency and total cost simultaneously and model the Web service location allocation problem as a multi-objective optimization problem. We develop a new PSO-based algorithm to provide a set of tradeoff solutions. The results show that the new algorithm can provide much more diverse sets of solutions than the compared multi-objective optimization algorithms. Moreover, the new algorithm has an excellent scalability and can maintain its competitive performance even for large problem instances.
\end{abstract}

% Note that keywords are not normally used for peer review papers.
\begin{IEEEkeywords}
Web service location allocation, Quality of Service, Evolutionary Computation, Particle Swarm Optimization.
\end{IEEEkeywords}}


% make the title area
\maketitle
\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}

\IEEEPARstart{I}{n} recent years, service-oriented computing (SOC) enables software applications to be developed in an agile and cost efficient way \cite{Dan:2008}. Web services are well-defined, self-contained modules that provide standard business functionality and can be accessed via the Internet \cite{Ran}. With the ever increasing number of functional similar web services being available on the Internet, the web service providers are trying to improve the quality of service (QoS) to become competitive in the market.
QoS, also known as non-functional requirements to web service, is the degree to which a web service meets specified requirements or user needs \cite{4061431}, such as response time, security, and availability. Among numerous QoS measurements, service response time is a critical factor for many real-time services, e.g. traffic service or finance service.

Service response time has two components: transmission time (variable with message size) and network latency \cite{Johansson}. Study \cite{916684} shows that network latency is a significant part of web service response delay. Ignoring network latency will underestimate response time by more than 80 percent \cite{Sun}. To reduce the network latency, large web service providers such as Google, Facebook or Microsoft have their high-bandwidth data centers. However, the majority of web service providers cannot afford to build a data center. Instead, they rent servers provided by web server hosting providers. Web service providers need to allocate their services wisely to minimize the overall network latency. According to a report from Alexa \cite{Alexa}, which is a popular web traffic analyzing company, 96\% of top one million web services were hosted in heterogeneous server clusters or co-location datacenters \cite{He} that were widely distributed across different geographic regions. Hence, it is necessary to provide an effective web service allocation guide to web service providers so that they can be benefited. This gives rise of the Web Service Location Allocation (WSLA) problem. Currently, many web service researchers \cite{7108071, chen2014web} have been aware of the WSLA problem and added location-awareness into their researches. However, few of research focuses on the service deployment stage.


The WSLA is very challenging because it has a combinatorial search space. For example, a WSP has 8 services to deploy at 4 locations. Each service can be deployed at multiple locations. Therefore, the total number of deployment solution is $2^{8 \times 4}$. It is hard for an exhaustive algorithm to find the optimal solution in such a huge search space.  In addition, the WSLA problem is essentially a multi-objective optimization problem \cite{Multiobjective} for which there are two potentially conflicting objectives, minimizing the response time and the total cost. In this case, there is no single global optimum, and the goal is to find a set of so-called Pareto-optimal solutions. 

Currently, very few studies focuses on WSLA problem. \cite{Aboolian, Sun} use traditional approaches, e.g. integer programming, to solve the problem. 
However, there are two issues with their models and methods. Firstly, they treat the WSLA problem as a single-objective problem and generate only one solution based on the an assumption that the service providers' preferences are known in advance. Secondly, their methods suffer from scalability problem \cite{klotz2013practical}, i.e. the computation time increases exponentially with the increasing number of variables. To address this drawback, various evolutionary algorithms such as genetic algorithm-based approaches (e.g. \cite{996017,knowles2000}) and Particle Swarm Optimization (PSO)-based approaches \cite{zhang2008multi} are promising alternatives due to their success in solving nonlinear discrete optimization problems. 

To address WSLA as a multi-objective problem, Multi-objective Evolutionary Optimization Algorithm (MOEA) methodologies are ideal \cite{key:article}, since MOEAs maintain a set (population) of solutions during the search process. With an emphasis on moving towards the true Pareto-optimal region, an MOEA algorithm can be used to find multiple Pareto-optimal solutions in one single simulation run \cite{OptimizationElectrical}.


In this paper, we explore effectiveness and efficiency of using MOEA approaches to solving WSLA problem. It has been discovered (\cite{godinez2010, hassan2005}) that PSO can achieve very promising performance when solving multi-objective optimization problems regarding both solution quality and computational efficiency. Therefore, in this paper, we consider a PSO-based multi-objective optimization framework to solve the WSLA problem.



In our previous work \cite{tan2016evocop} on WSLA, we studied the performance of applying three algorithms,  Binary PSO (BPSO), Binary Non-Dominated Sorting PSO (BNSPSO),  and a Genetic Algorithm (GA)-based multi-objective optimization algorithm (NSGA-II). We found that there are two significant shortcomings in BPSO, BNSPSO, and NSGA-II. The first one is that their performances drop rapidly when the problem size increases. The second is that the solutions are not diverse enough. To overcome these two drawbacks, we consider a Multi-Objective Particle Swarm Optimization with Crowding Distance (MOPSOCD). MOPSOCD is developed in \cite{Raquel} to produce a well-distributed set of non-dominated solutions. It has two desired features: \emph{an external archive set} and \emph{a mutation operator}. These two features make the algorithm have a strong ability to avoid being stuck at local optima while maintaining a uniformly distributed non-dominated set. 

However, the biggest obstacle of employing MOPSOCD in the WSLA problem is that MOPSOCD is a continuous optimization algorithm. It cannot be directly applied for solving WSLA, which is a discrete (binary) optimization problem. Therefore, we develop a new binary version of MOPSOCD, BMOPSOCD, to adapt to binary problems. To this end, we use \emph{rounding functions} to transform continuous values into binary ones. We propose three types of rounding functions and study their effects.

The overall goal is to develop a new binary multi-objective PSO-based approach to the WSLA problem by considering two potentially conflicting objectives - minimizing cost and minimizing network latency. More specifically, we have the following objectives:
\begin{enumerate}
  \item To design rounding functions for transforming continuous PSO to binary PSO;
  \item To develop a new multi-objective PSO approach that can produce a set of solutions with good diversity and can perform well when problem sizes increase;
 \item To evaluate our proposed approach by comparing it with previous approaches using some experiments.
\end{enumerate}


The paper is organized as follows. Section \ref{sec:related} reviews existing works and various PSO approaches and provides background knowledge of solving the problem. Section \ref{sec:prelimminary} describes the WSLA problem with formal models.  Section \ref{sec:methods} presents our approach of BMOPSOCD. Section \ref{sec:conclution} provides a conclusion and discusses the future work.

\section{Background}\label{sec:related}


\subsection{Related Work}

Most of the researchers treat the WSLA problem as a single-objective problem. \cite{Aboolian, Sun} tried to solve the problem by using integer linear programming techniques. In particular, \cite{Sun} solved this problem by employing greedy and linear relaxation. Huang et al. \cite{EnhancedGenetic} proposed an enhanced genetic algorithm (GA)-based approach on WSLA. They modeled the problem as a single-objective problem concerning response time.
Research on network virtualization \cite{export:149565,export:141114} employed greedy algorithms to allocate virtual machines (VMs) in a data center so that the requirements of network bandwidth are met. The major drawback of greedy algorithms is that they are easy to be stuck at local optima. \cite{6217521} presented a multi-layer and integrated fashion through a convex integer programming formulation. However, integer linear programming is well-known as not scaling very well. It performs poorly when the number of variables is large.


In the research field of cloud computing, web service placement is a similar task as WSLA. Instead of allocating web services in physical servers, web services are allocated in virtual machines. There are some existing works successfully applied MOEA in their problems. In particular, Kessaci et al. \cite{6557869} proposed an MOGA-CB for minimizing the cost of VMs instance and response time when considering web service composition as a workflow. \cite{Phan8} proposed a framework called GreenMonster, to dynamically move web services across Internet data centers for reducing their carbon footprint while maintaining their performance. Greenmonster applies a modified version of NSGA-II algorithm \cite{996017} with an additional local search process.


WSLA problem in nature is a multi-objective problem. In our previous work \cite{tan2016evocop}, we developed two PSO-based approaches, one with weighted-sum fitness function (named WSPSO), and the other using a binary fast Non-Dominate Sorting scheme (named BNSPSO). We study the performance of WSPSO, BNSPSO, and NSGA-II, one of the most commonly used multi-objective genetic algorithms with experimental evaluations. Our evaluation results show that both WSPSO and BNSPSO outperform NSGA-II while BNSPSO achieved a more diverse set of solutions than WSPSO. However, the performance of all the three approaches decreases while working on large datasets.


%From the previous study, we found MOEAs are promising. Specifically, among many MOEAs, multi-objective particle swarm optimization with crowding distance (MOPSOCD) is a recent development. It outperforms other approaches including NSGA-II, PAES in various aspects.
% Therefore, we decide to further improve the MOPSOCD and solve the Web service location allocation problem with it.

\subsection{Evolutionary Multi-Objective Optimization}

A multi-objective optimization problem consists of multiple objective functions to be optimized. Without loss of generality, we assume that all the objective functions are to be minimized. Therefore, a multi-objective optimization problem can be stated as follows:
\begin{align}
\min \ \ & \vec{f}(\vec{x}) = (f_1(\vec{x}), \dots, f_m(\vec{x})), \\
s.t. \ \ & \vec{x} \in \Omega.
\end{align}
where $\Omega$ stands for the feasible region of $\vec{x}$.

The objective functions $(f_1(\vec{x}), \dots, f_m(\vec{x}))$ are assumed to be conflicting, i.e. there is no single global optimal solution that achieves the optimal value for all the objective functions. In this case, the goal is to find a set of so-called \emph{Pareto-optimal} solutions. First, we introduce the concept of the \emph{dominance relation} between solutions in multi-objective optimization.
\begin{definition}[Dominance relation 1]
	A solution $\vec{x}_1$ is said to \emph{dominate} another solution $\vec{x}_2$ if 
	\begin{enumerate}
		\item for all $k \in \{1 \dots, m\}$, $f_k(\vec{x}_1) \leq f_k(\vec{x}_2)$ and
		\item there exists at least one $k \in \{1 \dots, m\}$, so that $f_k(\vec{x}_1) < f_k(\vec{x}_2)$.
	\end{enumerate}
\end{definition}
\begin{definition}[Dominance relation 2]
	Two solutions $\vec{x}_1$ and $\vec{x}_2$ are said to be \emph{non-dominated} to each other, if \emph{neither $\vec{x}_1$ dominates $\vec{x}_2$, nor $\vec{x}_2$ dominates $\vec{x}_1$}.
\end{definition}
Then, the Pareto optimality is defined as follows.
\begin{definition}[Pareto optimality]
	A solution $\vec{x}^*$ is a \emph{Pareto optimal solution}, if it is not dominated by any $\vec{x} \in \Omega$.
\end{definition}

Evolutionary Computation (EC) methods have shown to be competitive in solving multi-objective optimization problems due to its capability of maintaining a set of solutions in its population. This way, it can find a set of Pareto-optimal solutions in a single run. So far, Evolutionary Multi-objective Optimization (EMO) has been extensively studied, and numerous EMO algorithms have been proposed.
NSGA-II \cite{996017} is a widely used multiobjective algorithm. It proposed two innovative approaches, fast non-dominated sorting and an elitism selection operator, which are widely adopted by other optimization algorithms. SPEA2, an acronym for Strength Pareto Evolutionary Algorithm \cite{kim2004spea2}, is another landmark in this field. It uses an external archive to store non-dominated solutions and uses a nearest neighbor density estimation technique to guide the search process. MOEA/D \cite{zhang2007moea} has become one of the most 
popular multiobjective approaches in the recent decade. It introduces decomposition into evolutionary optimization which decomposes a multiobjective problem into a number of scalar optimization subproblems and optimizes them simultaneously. MOEA/D has a lower computational complexity than NSGA-II and a better performance on multiobjective 0-1 knapsack problems and continuous optimization problems.


\subsection{Particle Swarm Optimization (PSO)}
PSO was proposed by Kennedy and Eberhart in 1995 \cite{488968}. It is a population-based metaheuristic algorithm inspired by the social behavior of birds and fishes. In PSO, each individual is called a particle, which flies around the search space. The underlying phenomenon of PSO is optimized by the social interaction between particles to share information with each other.

At the initial state, each particle has a random initial position in the search space which is represented by a vector $\vec{x}_i = (x_{i1}, x_{i2}, \dots, x_{iD})$, where \emph{D} is the dimensionality of the search space. Each particle also has a velocity, which is represented as $\vec{v}_i = (v_{i1}, v_{i2}, \dots, v_{iD})$. The velocity is limited by a threshold $v_{\max}$ so that for any $i$ and $d$, $v_{id} \in [-v_{\max}, v_{\max}]$. During the search process, each particle maintains a record of its best position so far, called the \emph{personal best} ($pbest$). The best position among all the personal best positions of its neighbors is also recorded, which is called the \emph{global best} ($gbest$). The position and velocity of each particle are updated according to the following equations:

\begin{equation}
\label{eq:updatePosition}
 x^{t+1}_{id} = x^{t}_{id} + v^{t+1}_{id},
\end{equation}

\begin{equation}
\label{eq:updateVelocity}
 v^{t+1}_{id} = w \cdot v^{t}_{id} + c_1 \cdot r_{1i} \cdot (p_{id} - x^t_{id}) + c_2 \cdot r_{2i} \cdot (p_{pg} - x^i_{id}).
\end{equation}

In here, $t$ is the index of iteration. \emph{d} is the index of dimension. \emph{w} is the inertia weight used to balance the local search and
global search abilities of PSO. $c_1$ and $c_2$ are the acceleration constants. $r_{1i}$ and $r_{2i}$ are random constants following the uniform distribution in the interval $[0, 1]$. $p_{id}$ and $p_{gd}$ denote the values of $pbest$ and $gbest$ in the $d^{th}$ dimension of the $i^{th}$ particle.

PSO was originally developed to address continuous optimization problems with a single objective. The representation of both position and velocity of a particle in PSO is a vector of real numbers. However, this representation is not suitable for discrete optimization problems. To address discrete optimization problems, in 1997 Kennedy and Eberhart developed a binary particle swarm optimization (BPSO) \cite{637339}. In BPSO, the position of each particle is a vector of binary numbers, which are restricted to 1 or 0. The position update scheme is modified accordingly so that the updated position is guaranteed to be binary. We applied BPSO in WSLA in previous study \cite{tan2016evocop}. Since BPSO is a single-objective algorithm, we used the linear aggregation (weighted sum) approach to transform the multiple objective values into a single aggregated value. The result shows that BPSO provides a narrow range of solutions. That is because the evolution process is directed by the fixed weights of the objectives. As a result, BPSO evolves in the same direction as the predefined weight vector, and loses the capability of exploring other regions. Consequently, single-objective BPSO is impossible to provide a diverse set of solutions. 


Several multi-objective optimization algorithms are based on PSO such as Multi-Objective PSO (MOPSO) \cite{1304847}, and Non-Dominated Sorting PSO (NSPSO) \cite{NSPSO}. \cite{1304847} studies the performance of four multi-objective algorithms,   NSGA-II \cite{996017}, PAES \cite{knowles2000}, Micro-GA \cite{Micro} and MOPSO, and shows that MOPSO is most capable of generating the best set of non-dominated solutions close to the true Pareto front but with low computational cost. To improve the diversity of non-dominated solutions, Raquel et al. \cite{Raquel} propose an MOPSOCD extended from the MOPSO. The mechanism of crowding distance is incorporated into the algorithm on a global best selection of an external
archive of non-dominated solutions. Due to its competitiveness of generating a well-distributed set of non-dominated solutions, in this paper, we develop a binary version of MOPSOCD to solve the WSLA problem.

%Pareto front approach was first introduced by Goldberg in \cite{goldberg1988genetic}. Goldberg suggested using nondominated ranking and selection to move a population to the Pareto front. This idea currently is the mainstream in MOEA.

%NSGA-II is a multi-objective algorithm based on genetic algorithm (GA). It was proposed by Klyanony et.al \cite{996017} in 2002. NSGA-II performs well in convergence and permits a remarkable level of flexibility. It has four innovative properties, a fast non-dominated sorting procedure, an elitist strategy, a parameterless approach and an efficient constraint-handling method.



\section{Problem Description} \label{sec:prelimminary}

In this work we consider the WSLA as a multi-objective problem with two potentially conflicting objectives, minimizing the total deployment cost and minimizing the network latency. In this section, we first describe the WSLA problem in detail.  Then we introduce matrices for modeling the input and output information of the problem.

To solve the WSLA problem we consider a set of user centers $\mathcal{U }= \{U_1, \dots, U_m \}$ and a set of candidate locations $\mathcal{A} = \{A_1, \dots, A_n\}$. A user center can be a centre location of a user-centered area. Candidate locations are the geographic location that are suitable to deploy web services, e.g., the locations of servers hosting web services. A service provider needs to deploy a set of web services $\mathcal{W} = \{W_1, \dots, W_s\}$, each of which needs to be deployed to at least one location. Note that a web service can be deployed to multiple locations for the benefit of reducing service response time. For each web service $W_i \in \mathcal{W}$ and each candidate location $A_j \in A$, there is a deployment cost $C_{ij}$ induced by deploying service $W_i$ to candidate location $A_j$. Service invocation frequency $F_{ki}$ denotes the service invocation frequencies from user center $U_k$ to services $W_i$. In real life, a service invocation frequency is fluctuated over time, therefore, it is hard to use. Instead, we take an average number of invocations over a period of time to represent the frequency.   For each user centre $U_k \in \mathcal{U}$ and each candidate location $A_j \in \mathcal{A}$, there is a latency $L_{kj}$, which affects the response time from the location $A_j$ to the user center $U_k$. Since the networking topology between two locations is complex and changes over time, we treat it as a black box and use network latency to represent the network distance between two locations. We use a \emph{service location matrix} $X = [X_{ij}]$ to represent the location allocation plan, where $X_{ij}$ represents whether a service $W_i$ is deployed at a candidate location $A_j$ or not.
 Given the information above, WSLA is to design an allocation plan that allocates a set of services $\mathcal{W} = \{ W_1, W_2, \dots,  W_s\}$  to a set of candidate locations $\mathcal{A}= \{ A_1, A_2, \dots,  A_n \}$ so that the total deployment cost $f_1$ and response time $f_2$ are minimized. Total deployment cost $f_1$ and total network latency $f_2$ can be calculated as follows:

\begin{equation} \label{eq:fit-cost}
\begin{aligned}
& & &  f_1 = \sum\limits_{i=1}^s \sum\limits_{j = 1}^n C_{ij} X_{ij},
\end{aligned}
\end{equation}

\begin{equation} \label{eq:fit-latency}
\begin{aligned}
& & & f_2 = \sum\limits_{k=1}^m \sum\limits_{i=1}^s F_{ki} R_{ki},
\end{aligned}
\end{equation}

\noindent where $X_{ij}$ takes 1 if service $W_i$ is allocated to location $A_j$, and 0 otherwise. $R_{ki}$ stands for the shortest response time of accessing service $W_i$ from user center $U_k$, which is calculated as
 \begin{equation}
 \label{eq:response}
  R_{ki} = \min\{L_{kj} \mid j \in \{1, 2, ..., k\} \text{ and } X_{ij} = 1\}
 \end{equation}



WSLA has the following two objective functions and one constraint.
\begin{equation} \label{eq:cost}
\begin{aligned}
& {\text{minimize}}
& &  f_1 = \sum\limits_{i=1}^s \sum\limits_{j = 1}^n C_{ij} X_{ij},\\
\end{aligned}
\end{equation}


\begin{equation}
\begin{aligned} \label{eq:latency}
& {\text{minimize}}
& & f_2 = \sum\limits_{k=1}^m \sum\limits_{i=1}^s F_{ki} R_{ki},\\
\end{aligned}
\end{equation}


\begin{equation} \label{eq:constraint}
\begin{aligned}
& \text{subject to}
%& & \displaystyle \sum_{j} a_{sj} \geqslant 1
& &  \sum_{j=1}^n X_{ij} \geqslant 1, \forall i \in {1, \cdots, s}\\
& & & x_{ij} \in {0, 1}, \forall i \in {1, \cdots, s}, \forall j \in {1, \cdots, n},
\end{aligned}
\end{equation}


% In this paper, we will use the following matrices to model the above mentioned information.
% \begin{center}
% {
% %\centering
%  \footnotesize
%  \begin{tabular}{l*{2}{l}r}
%   \hline
%   \textbf{Matrices} \cr
%   $L$ & server network latency matrix $L = \{l_{kj}\}$ \cr
%   $A$ & service location matrix $X = \{x_{ij}\}$ \cr
%   $F$ & service invocation frequency matrix $F = \{f_{ki}\}$ \cr
%   $C$ & cost matrix $C = \{c_{ij}\}$ \cr
%   $R$ & user response time matrix $R = \{r_{ki}\}$ \cr
%   \hline
%  \end{tabular}
% \\
% }
% \end{center}

The aim of WSLA is to find a location-allocation matrix $X = [X_{ij}]$ such that it results in minimal overall network latency and overall deployment cost.

For example, assume we are given the service invocation frequency matrix $F$, latency matrix $L$, deployment cost matrix $C$, and the allocation plan matrix $X$ as follows, we will show how to calculate the overall deployment cost and network latency.

\noindent\parbox{.45\linewidth}{
 {\centering
%   \begin{equation*}
\begin{displaymath}
\begin{aligned}
F = \bbordermatrix{~ & W_{1} & W_{2} & W_{3}  \cr
					U_{1}	&120 &35 &56	\cr
					U_{2}	&14  &67 &24 \cr
					U_{3}	&85 &25 &74 \cr}, 
\end{aligned}
%\end{equation*}
\end{displaymath}
 \\}
 }
 \parbox{.45\linewidth}{
 {\centering
 \begin{displaymath}
\begin{aligned}
\;\;\;\;\; L = \bbordermatrix{~ & A_{1} & A_{2} & A_{3} \cr
 					U_{1}	&0 &5.7 &6.9	\cr
 					U_{2}	&5.7  &0 &2.0 \cr
 					U_{3}	&0.9 &1.1	&2.3 \cr}.
\end{aligned}
\end{displaymath}
 \\}
 }

% For example, the network latency between user center $i_{2}$ with candidate location $j_{1}$ is 5.776s. These data could be collected by monitoring network latencies \cite{6076756} \cite{5552800}.


%For example, $c_{12} = $ 80 denotes the cost of deploying service $s_{1}$ at candidate location $j_{2}$ is 80 cost units.
%
\noindent
 \parbox{.46\linewidth}{
 {\centering
 \begin{equation*}
\begin{aligned}
C = \bbordermatrix{~ & A_{1} & A_{2} & A_{3}\cr
 					W_{1}	&130 &80 &60\cr
					W_{2}	&70  &50 &30\cr
 					W_{3}	&40 &78 &54\cr},
 \end{aligned}
\end{equation*}
\\ }
 }
 \parbox{.46\linewidth}{
 {\centering
 \begin{equation*}
\begin{aligned}
\;\;\;\; X = \bbordermatrix{~ & A_{1} & A_{2} & A_{3}\cr
 					W_{1}	&0 &1 &0	\cr
 					W_{2}	&0  &0 &1	\cr
 					W_{3}	&1 &1 &0	\cr}
\end{aligned}
\end{equation*}
 \\}
 }

The calculation of the overall deployment cost is straightforward. It is simply summing up the deployment costs of all the deployments as follows.
\begin{align*}
f_1 & = \sum\limits_{1=1}^s \sum\limits_{j = 1}^n C_{ij} X_{ij}\\
& = C_{11} X_{11} + C_{12} X_{12} + C_{13} X_{13} + ... + C_{33} X_{33} \\
& = 130 * 0 + 80 * 1 + 60 * 0 + ... + 54 * 0 \\
& = 228
\end{align*}

To calculate the overall network latency, we need to first calculate the response time matrix $R$ using the matrices $L$ and $X$. For each service $W_i$, by checking matrix $X$, we can find out which locations the service have been deployed. Then, check matrix $L$ to find out the corresponding latency from each deployed location $A_j$ to each user center $U_k$. Finally, the smallest latency is selected to be the response time from each service $W_i$ to each user center $U_k$. In the above example, the corresponding response matrix is
$$
R = \bbordermatrix{~ & W_{1} & W_{2} & W_{3}\cr
	U_{1}	&5.7 &6.9 &0	\cr
	U_{2}	&0  &2.0 &0	\cr
	U_{3}	&1.1 &2.3 &0.9	\cr}
$$

Finally, we can calculate the overall network latency as
\begin{equation*}
\begin{aligned}
f_2 & = \sum\limits_{k=1}^m \sum\limits_{i=1}^s F_{ki} R_{ki}\\
  & = F_{11} R_{11} + F_{12} R_{12} + F_{13} R_{13} + ... + F_{33} R_{33} \\
  &= 120 * 5.7 + 35 * 6.9  + 56 * 0  + ... + 74 * 0.9\\
  &= 1277.1
\end{aligned}
\end{equation*}

Note that the constraint requires that each web service is deployed to at least one location. The example matrix $X$ above satisfies the constraint.


\section{BMOPSOCD for Web Service Location Allocation} \label{sec:methods}

In this section, we present our approach of BMOPSOCD to solve the WSLA problem. We first define the representation of the problem followed by different rounding methods that transform a continuous representation to a binary representation. We then present fitness functions to be used, and our method of handling the constraint, followed by our proposed BMOPSOCD algorithm for WSLA.

\subsection{Particle Representation}

As we see from above that WSLA is to design a location allocation matrix $X =[X_{ij}]$, where $i = 1,...,s$ and $j=1,...,n$.  The major difference between BMOPSOCD and three previous approaches, WSPSO, BNSPSO and NSGA-II,  is the particle representation. As mentioned in Section \ref{sec:prelimminary}, the solution of WSLA is a $s \times n$ matrix. As we known that PSO can be used to generate vector-based solutions, we need to transform the $s \times n$ matrix into a  $(s \times n)$ dimensioned vector $y$. The element $X_{ij}$ in $X$ corresponds to the $ (n \cdot (i-1) +j)^{th}$ element in $Y$. Also, for continuous PSO, each element of a particle takes value from 0 to 1, i.e., $0 \leq  Y_u  \leq 1$. For example, the following $3 \times 3$ matrix

 \begin{equation*}
\begin{aligned}
 X = \bbordermatrix{~ & A_{1} & A_{2} & A_{3} \cr
      W_{1} &0.12 &0.87 &0.42 \cr
      W_{2} &0.07  &0.32 &0.95 \cr
      W_{3} &0.76 &0.64 &0.27 \cr}\\
\end{aligned}
\end{equation*}\\
can transformed into a vector:
$$
Y = [0.12, 0.87, 0.42, 0.07, 0.32, 0.95, 0.76, 0.64, 0.27].
$$

As we know that the final output of WSLA is an allocation matrix with $X_{ij}$  as a binary value, the particle with the continuous representation needs to be transformed into the binary representation, using rounding methods. The choice of the rounding function plays an important role in the quality of the final results. In the following sections, we will discuss different rounding methods. Note that the vector $Y$ is used in the update phase of our PSO-based algorithm. During the fitness evaluation phase, each $Y$ is first decoded into a matrix $X$ with the selected rounding function.

% \begin{figure}[H]
% \centering
%   \includegraphics[width=0.35\textwidth]{pics/flatten.eps}
%   \caption{BMOPSOCD particle representation}
%   \label{fig:flatten}
% \end{figure}


\subsection{Rounding Functions}

The original MOPSOCD is designed as a continuous version of PSO. Instead of changing the particle to a binary representation, we still use the continuous representation. On one hand, it is because the binary position updating function (Eq. \ref{eq:binaryUpdate}) is frequently criticized for being independent between the current value and the next value \cite{khanesar2007novel}. On the other hand, the position updating of continuous PSO is a well-defined mechanism. Therefore, we keep the continuous representation and related evolutionary operators. Furthermore, we explore using rounding functions as a mechanism of transferring a continuous representation to a binary representation.

 \begin{equation}
  \label{eq:binaryUpdate}
  x^{t+1}_{id} =
  \begin{cases}
   1 & \quad \text{if } rand() < \frac{1}{1 + e^{-v_{id}(t + 1))}} \\
   0 & \quad \text{otherwise} \\
  \end{cases}
 \end{equation}

That is, at the initial stage, particles are initialized in real values as before. The updates of velocity and position are performed as usual. At the evaluation stage, particles in continuous representation need to be transformed to the particles in a binary representation, which can then be evaluated by fitness functions. Notice that a particle does not change after evaluation, only its ``binary representation'' is evaluated. 

The rounding function is used to map a real-valued particle to a discrete-valued particle. The common strategy is to round a real-valued to its closest integer number. The round-down strategy is adopted in \cite{1004478} to solve integer programming problem. \cite{xue2013particle} defines a static rounding function for feature selection problem. Whether a feature is selected or not is determined by a predefined static threshold $\theta$. \cite{4120263} uses a real-valued representation of chromosome for GA. Then, a real-valued chromosome is rounded to an integer representation. \cite{liu2013discrete} adopts rounding and interval mapping strategy to solve 0-1 discrete, integer optimization and mixed optimization problem. \cite{Anghinolfi200973} uses a random rounding function which randomly returns round-up value or round-down value. Nonetheless, there is no thorough study of how to choose rounding functions or a comparison between different rounding functions. Hence, we propose three types of rounding functions and study their characteristics. We would start with the most simple form --- the static rounding function.


\subsubsection{Static Rounding Function}

The static rounding function is a straightforward strategy. As shown in Equation \ref{eq:1}, a parameter threshold $t$ is introduced in the static rounding function.
The value of a particle entry $X'_{ij}$ is either round up or round down according to $t$.
The threshold value $t$ is rather ad-hoc and is usually set based on empirical study.
 \begin{equation}
  \label{eq:1}
  X_{ij} =
  \begin{cases}
   1 & \quad \text{if } X'_{ij} > t \\
   0 & \quad \text{otherwise} \\
  \end{cases}
 \end{equation}


\subsubsection{Dynamic Rounding Functions}
\label{sec:dynamic}
The threshold plays an important role in searching for solutions for a given problem \cite{tan2016evocop}. The static rounding function has the following drawbacks. Firstly, the threshold $t$ needs to be predefined. Because the threshold is problem specific, therefore, it is hard to estimate the effect of $t$ before observing the performance of results. Secondly, the influence of different threshold values is not completely studied. Because of the above reasons, a dynamic rounding threshold is proposed. A dynamic rounding function has two steps. In the first step, it adjusts the value of threshold $t$ according to a function with two predefined parameters: a lower boundary $l$ and an upper bound $u$ of the threshold ($l < u$), and a dynamic parameter: the current generation $g$. In the second step,  same as the static rounding function, it either rounds up or rounds down the value of $X_{ij}$ according to $t$. Three dynamic rounding functions are considered. Equation \ref{eq:linear} is a \emph{linear function}. Equation \ref{eq:quadratic} is a \emph{Quadratic function}. Equation \ref{eq:reciprocal} is a \emph{Reciprocal function}, specifically, current generation $g$ can not equal $max\_gen$ in order to keep the result valid. 
\begin{equation}
\label{eq:linear}
 t_{linear} = \frac{l - u}{\text{max\_gen}} g + u
\end{equation}

\begin{equation}
\label{eq:quadratic}
 t_{quad} = \frac{l - u}{(\text{max\_gen})^2} g^2 + u
\end{equation}

\begin{equation}
\label{eq:reciprocal}
 t_{recip} = u - \frac{u - l}{\text{max\_gen} - g}  (g \neq \text{max\_gen})
\end{equation}

The reason that we design three dynamic functions is that we would like to compare the impact of different trajectories of dynamic thresholds; the three dynamic functions' trajectories are shown in Figure \ref{fig:dynamic} with $l$ is set to 0.3, $u$ is set to 0.7, and $max\_gen$ is set to 50 as an example. It is easy to notice that the threshold values with a Linear function are uniformly distributed. The threshold values on Reciprocal and Quadratic functions are unevenly distributed. That is, concentrated at the first half and gradually becoming sparse. The performances of these rounding functions are studied in Section \ref{sec:expdy}.


\begin{figure}[H]
\centering
  \includegraphics[width=0.35\textwidth]{pics/dynamic.eps}
  \caption{Trajectories of the three dynamic thresholds}
  \label{fig:dynamic}
\end{figure}
%
% The parameter $threshold$ is an empirical parameter that introduced into the algorithm.
\subsubsection{Stepped Rounding Function}
\label{sec:transfer}
% As the problem becomes getting larger and larger, the performance of evolutionary computation drops.
A human can learn a technique or knowledge and apply in different fields.
As the dimensionality of the problem increases, the performance of evolutionary computation drops.
It is necessary to build a system that can reuse the learned knowledge.
Transfer learning is a process to reuse the knowledge in solving unseen tasks \cite{olivas}.
In this section, we propose a stepped rounding function that is embodied in the transfer learning process.

Figure \ref{fig:adaptive} shows the evolutionary process with a stepped rounding function. % The idea of transfer learning is inspired by \cite{Verbancsics}.
Initially, the threshold $t$ is set to an upper boundary $u$ (e.g. 0.7). Then the PSO runs with this setting for a predefined interval of $i$ (e.g. 10) generations. At the beginning of the next interval (e.g. 11) generation, the threshold $t$ is changed according to Equation \ref{eq:transfer} and remain unchanged until next interval. This process is repeated until the lower boundary $l$ is reached. The optimization may look like forcing the swarm to ``jump'' to a different area. But the process is equivalent to initializing a new set of a population with the old one. Therefore, the knowledge is inherited. An underlying assumption is that, if the particle swarm has converged within an interval, then it is better to explore a different direction. Therefore, in the next interval, the swarm will explore a slightly different area and is directed by an adjacent threshold value. The potential problem of the method is that it is hard to know whether the PSO is converged. The transfer learning rounding function is shown in Equation \ref{eq:transfer} where $t'$ denotes the current threshold value.

\begin{figure}[H]
 \centering
   \includegraphics[width=0.4\textwidth]{pics/transfer.eps}
   \caption{Evolutionary process with a stepped rounding function}
   \label{fig:adaptive}
 \end{figure}

\begin{equation}
\label{eq:transfer}
  t =
  \begin{cases}
   t' - \frac{u - l}{(\text{max\_gen}/i - 1)} & \quad \text{if } (\text{cur\_gen}\mod i) = 0\\
   t' & \quad \text{otherwise} \\
  \end{cases}
\end{equation}



\subsection{Fitness Function and Constraint Handling}

After the particles that are represented as vectors have been transformed to allocation matrices, two fitness functions, Equation \ref{eq:fit-cost} and \ref{eq:fit-latency},  are used to evaluate the fitness of particles that represent location allocation plans. Based on the fitness of solutions a set of non-dominated solutions are returned.

As we see in Section \ref{sec:prelimminary}, WSLA needs to satisfy the constraint defined by Equation \ref{eq:constraint}, which means that each service needs to be allocated to at least one location. However, during the searching process of PSO, the constraint may be violated. That is, some services might be allocated to none of the locations during the process of searching.

%As in \cite{tan2016evocop}, we employ a penalty method, named \emph{death penalty}, to assign infeasible particles the highest possible fitness values. Specifically,

%\begin{equation*}
%\hat{f}_i(Y) =
%  \begin{cases}
%   \hat{f}_i(Y)  & \quad \text {if } $Y$ \text{ is feasible}\\
%   1 & \quad \text{otherwise} \\
%  \end{cases}, i = 1, 2.
%\end{equation*}

The constraint handling method used by BMOPSOCD is a ranking of violations. A solution $I$ is considered to constraint-dominate a solution $J$ if any of the following conditions is true:
\begin{enumerate}
 \item Solution $I$ is feasible while solution $J$ is not,
 \item Both solutions are infeasible and solution $I$ has less violation,
 \item Both solutions are feasible, and solution $I$ dominates solution $J$.
\end{enumerate}

The particle with less violations is always considered as a better solution. If there is only one constraint, this constraint handling method provides the same effect as the death penalty method in \cite{coello2002theoretical}.

\subsection{The BMOPSOCD algorithm for Web Service Location Allocation}

Algorithm \ref{alg:BMOPSOCD} presents our BMOPSOCD algorithm for solving the WSLA problem. As seen in the algorithm, the selection of $pbest$ and $gbest$ is one of the key steps in BMOPSOCD. $pbest$ is the personal best solution of each particle in population. The $pbest$ is updated only if the new particle dominates the current one. Otherwise, it remains unchanged. In the BMOPSOCD, any non-dominated solutions in the archive can be a $gbest$. Therefore, it is important to ensure that the particles move to an unexplored area. The $gbest$ is selected from non-dominated solutions with the highest crowding distance value. It ensures that the swarm move to a less crowded area.


\begin{algorithm}[!htb]
 \caption{BMOPSOCD for WSLA}
 \footnotesize
 \textbf{Inputs:} \\
  Cost Matrix $C$, \\
  Server network latency matrix $L$, \\
  Service invocation frequency matrix $F$ \\
 \textbf{Outputs:}
  Pareto Front: the $Archive$ set

 \begin{algorithmic}[1]
  \State Initialize each individual $X_{ij}$ in a Population $P$ with a random real value $\in$ (0, 1).
  \State Initialize $v_i$ = 0
  \State \textbf{For each individual $i$ in $P$ Rounding and Evaluating fitness}
  \State Initialize $pbest$ of each individual $i$.
  \State Initialize $gbest$
  \State Initialize $Archive$ with non-dominated vectors in $P$

  \Repeat
   \State Compute the crowding distances of each solution $i$ in $Archive$
   \State Sort solutions in $Archive$ in descending crowding distances
   \For ( each particle)
    \State Randomly select the global best guide for $P[i]$ from a specified top portion of the sorted archive $A$ and store its position to $gbest$.
    \State Compute the new velocity $v_i$ using Eq.\ref{eq:updateVelocity}
    \State Update its position $x_i$ using Eq.\ref{eq:updatePosition}
    \State If X $>$ 1 or X $<$ 0, set its value to 1 or 0 and multiply its velocity by -1.
    \State If ($t < (MAXT * PMUT)$), apply Mutation
    \State \textbf{Rounding and Evaluating fitness}
    \State Update its $pbest$
    \EndFor
  \State Insert new non-dominated solution into $Archive$, remove dominated solutions from $Archive$
  \Until{ maximum iterations is reached}
  \State return $Archive$
 \end{algorithmic}
 \label{alg:BMOPSOCD}
\end{algorithm}

The fitness of particles can be evaluated using the objective functions presented in Equation  \ref{eq:fit-cost} and \ref{eq:fit-latency}. Line 12 updates velocity $v_i$ as:
\begin{equation}
 v_{id} = w * v_{id} + c_1 * r_{1i} * (p_{id} - x_{id}) + c_2 * r_{2i} * (p_{pg} - x_{id})
\end{equation}
\noindent where $w$ is the inertia weight, $c_1$ and $c_2$ are the acceleration factors, $r_{1i}$ and $r_{2i}$ are the random variables sampled from the uniform distribution between 0 and 1, $v_{id}, x_{id}, p_{id}$ and $g_{d}$ denote the value in dimension $d$ of $\vec{v_i}, \vec{x_i},\vec{p_i}$ and $\vec{g}$, respectively.  Note that the main difference between our algorithm and the one in \cite{Raquel} is in Lines 3 and 16, which is the rounding function that transforms the continuous vector to a binary one. For WSLA, the decision variable is binary, 0 or 1. Therefore, in our algorithm (Line 3 and 16) we apply a rounding function to transform continuous values to binary values.



%\section{Experiment Design}

\section{Experiment Design} \label{sec:experiment}
\label{sec:exp}

The aim of this study is to propose a multi-objective WSLA approach which can produce well-distributed solutions with good scalability. In the above section, we present our BMOPSOCD approach to the problem of WSLA. For this approach, static and dynamic rounding methods with different threshold settings are considered.  In this section, a set of experiments have been conducted over three major features of the proposed algorithm. The first feature considers the static threshold. The influence of the selection of different values of a static threshold is studied in the first experiment. The second feature is the dynamic rounding functions used in the algorithm. Three types of rounding functions are examined in the second experiment. The third feature is the stepped rounding function. Its performance is studied in the third experiment. 
We also made a comparison between a dynamic function with a congregation of
several static rounding functions with different thresholds. Lastly, we conduct an experiment considering the overall performance of a BMOPSOCD with a dynamic rounding function in comparison with three other algorithms: PSO, BNSPSO and NSGA-II (see \cite{tan2016evocop} for details).

\subsection{Datasets}
\label{sec:datasets}
This project is based on both real-world datasets \textit{WS-Dream} \cite{6076756,5552800} and simulated datasets \cite{tan2016evocop}. The \textit{WS-Dream} includes a network latency matrix between 339 user centers and 5825 candidate locations. In this project, there are mainly three attributes that need to be provided, network latencies between candidate locations and user centers,  deployment cost in candidate locations, and web service invocation frequency information as mentioned in Section \ref{sec:prelimminary}. In principle, deployment cost can be either fixed fees (monthly rent) or variable fees (e.g. depending on storage and other resource usages). For the sake of simplicity, we consider fixed deployment fee. For each service, the deployment cost was randomly generated from a normal distribution with the mean of 100 and standard deviation of 20. For each user center and each service, the invocation frequency was randomly generated from a uniform distribution between 1 and 120. To test the scalability of our proposed approach, we design a set of problems with different complexities.

Table \ref{tab:problem} shows fourteen problems, listed with increasing size and difficulty, which are used as representative samples of the WSLA problem.

\begin{table}[H]
\footnotesize
\centering
\caption{Problem set}
\label{tab:problem}
\begin{tabular}{l|c|c|c}
\hline
Datasets   & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}No. of \\ Services\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}No. of \\ Candidate Locations\end{tabular}} & \multicolumn{1}{l}{\begin{tabular}[c]{@{}l@{}}No. of \\ user centers\end{tabular}} \\ \hline
Problem 1  & 20                                                                             & 5                                                                                         & 10                                                                                  \\ \hline
Problem 2  & 20                                                                             & 10                                                                                        & 10                                                                                  \\ \hline
Problem 3  & 50                                                                             & 15                                                                                        & 20                                                                                  \\ \hline
Problem 4  & 50                                                                             & 15                                                                                        & 40                                                                                  \\ \hline
Problem 5  & 50                                                                             & 25                                                                                        & 20                                                                                  \\ \hline
Problem 6  & 50                                                                             & 25                                                                                        & 40                                                                                  \\ \hline
Problem 7  & 100                                                                            & 15                                                                                        & 20                                                                                  \\ \hline
Problem 8  & 100                                                                            & 15                                                                                        & 40                                                                                  \\ \hline
Problem 9  & 100                                                                            & 25                                                                                        & 20                                                                                  \\ \hline
Problem 10 & 100                                                                            & 25                                                                                        & 40                                                                                  \\ \hline
Problem 11 & 200                                                                            & 25                                                                                        & 40                                                                                  \\ \hline
Problem 12 & 200                                                                            & 25                                                                                        & 80                                                                                  \\ \hline
Problem 13 & 200                                                                            & 40                                                                                        & 40                                                                                  \\ \hline
Problem 14 & 200                                                                            & 40                                                                                        & 80                                                                                  \\ \hline
\end{tabular}
\end{table}



\subsection{Performance Metrics}

We use HyperVolume (HV) and IGD as the evaluation metrics. The IGD \cite{1501598} is a modified version of generational distance \cite{veldhuizen99, 870296} as a way of estimating how far the elements in the true Pareto front are from those in the non-dominated set produced by an algorithm. It calculates the sum of the distances from each point from the true Pareto front to the nearest point from the non-dominated set produced by an algorithm. The lower the IGD, the better quality the solution is. A true Pareto front is needed when calculating the IGD value. For our problem, the true Pareto front is unknown. Therefore, an approximated Pareto front is produced by combining all the solutions produced by the four compared algorithms (BMOPSOCD, NSGA-II, BNSPSO, BPSO) and then applying a non-dominated sorting to obtain the final non-dominated set. The approximated true Pareto front dominates all the other solutions we found.

\subsection{Parameter Settings}

 
The parameters of the PSO algorithms are set as follow, $w$ = 0.4, mutation probability $P_m$ = 0.5, $c_1$ = 1, $c_2$ = 1, archive size is 250, population size is  50 and the max number of iteration is 50. For each experiment, the proposed algorithm has been independently run for 40 times. The best results of all the runs are compared.  To obtain the \emph{best result} of 40 runs, the results of all 40 runs are combined and sorted by the fast non-dominated sorting \cite{996017}.
 

\subsection{Experiments on Rounding Functions}
This section designs four experiments to study the effect of different types of rounding functions. Four datasets (Problems 2 $\sim$ 5) are used, chosen from Table \ref{tab:problem}.

% The cost constraint is not considered in these experiments since it is not the study priority.
% The repair function of NSGA-II will also only use the Web service number constraint.

\subsubsection{Static Rounding Function}
\label{sec:static_exp}
There are two questions that we would like to answer with this experiment. The first question is \textit{what the influence of the threshold is}. The second question is \textit{how to select a proper static threshold}. To answer these two questions, a set of experiments is conducted to evaluate the performance of various threshold values ranging from 0.3 to 0.7. 

\subsubsection{Dynamic Rounding Function}
In Section \ref{sec:dynamic}, three dynamic rounding functions are proposed. In this section, we evaluate the performances of these three rounding functions to find out which dynamic rounding function provides the best results.  The upper boundary of dynamic threshold $u$ is set to 0.7 and the lower boundary of dynamic threshold $l$ is set to 0.3. The results are compared in terms of mean IGD and HV.

\subsubsection{Stepped Rounding Function}
The performance of the stepped rounding function is studied in this experiment. The upper boundary of dynamic threshold $u$ is set to 0.7 and the lower boundary of dynamic threshold $l$ is set to 0.3. The interval is set to 10 generations. The results are compared with dynamic functions.

\subsubsection{Result Analysis of Static Rounding Function}
We plot the results in Figure \ref{fig:staticFunctions}, each color represents a threshold value and each point denotes a service location allocation solution which is represented with its two fitness values: latency and cost. It clearly shows that the BMOPSOCD with a specific static threshold could provide a set of non-dominated solutions which partially covers the Pareto front. 

The impact of a static threshold can be explained as a preference factor between two objectives. Take the threshold value of 0.7 as an example, 
when the rounding function rounds a real value to a binary value with respect the threshold 0.7, it means that 70\% of probability rounds this value to zero. It denotes that there are 70\% of chance does not deploy a web service in a location. 
Intuitively, the optimization with threshold of 0.7 would consider optimizing cost over latency by deploying fewer web services. The swarm is under the 
guidance of this ``savings'' policy. This effect can be observed on all four problems, where the solutions with 0.7 threshold 
scattered along the area with lower cost and higher latency (e.g. orange points). On the other hand, the solutions with $t$ that is less than 0.5 favor quality
over cost, that is, more web services are deployed.

The experimental results clearly answered the first question: \textit{the influence of different thresholds}. 
However, it does not offer a guideline for selection of a proper threshold, because none of the solutions could cover the entire Pareto front.
Worth noting that, a set of combining all the results is ideal, as it largely improves the diversity of the non-dominated set. However, simply repeating the experiment with different threshold values is time consuming. It is necessary to discover a method with widely spread solutions as well as a low computational complexity.
This motivation inspires the development of the dynamic rounding functions.
\begin{figure}[h!]
   \centering
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/static_threshold_problem_2.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/static_threshold_problem_3.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/static_threshold_problem_4.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/static_threshold_problem_5.png}
    \caption{}
   \end{subfigure}
   \caption{Static Rounding Function Experiments : Solutions from Problem 2 to 5 with different static threshold values}
   \label{fig:staticFunctions}
\end{figure}

\subsubsection{Comparison between Dynamic Rounding Functions}
\label{sec:expdy}
Table \ref{tab:hyperDynamic} shows the average performance of three dynamic functions that are evaluated by hypervolume.
The results indicate that the Reciprocal function dominated the three dynamic functions in all test cases. This could be visually observed by plotting the best results (Figure \ref{fig:dynamicFunctions}).
Figure \ref{fig:dynamicFunctions} shows that the Reciprocal function slightly dominates the other two dynamic functions. However, the problem of the Reciprocal function is that the solutions are not complete. There are gaps for the blue points in Problems 3 $\sim$ 5. The gap is created because of the lack of uniformity of the Reciprocal function (Figure \ref{fig:dynamic}).

\begin{figure}[h!]
   \centering
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/dynamic_problem_2.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/dynamic_problem_3.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/dynamic_problem_4.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/dynamic_problem_5.png}
    \caption{}
   \end{subfigure}
   \caption{Dynamic Rounding Function Experiments : The non-dominated solutions among the sets obtained by 40 independent runs of BMOPSOCD with different dynamic functions}
   \label{fig:dynamicFunctions}
\end{figure}


\begin{table}[H]
\centering
\footnotesize
\caption{The mean and standard deviation of the hypervolume values over the 40 independent runs}
\label{tab:hyperDynamic}
\begin{tabular}{l|c|c|c}
\hline
          & \multicolumn{1}{l|}{Linear} & \multicolumn{1}{l|}{Quadratic} & \multicolumn{1}{l}{Reciprocal}  \\ \hline
problem 2 & 0.72 $\pm$ 0.011            & 0.73 $\pm$ 0.008               & \textbf{0.74 $\pm$ 0.013}    \\
problem 3 & 0.80 $\pm$ 0.012            & 0.81 $\pm$ 0.012               & \textbf{0.815 $\pm$ 0.013}    \\
problem 4 & 0.82 $\pm$ 0.012            & 0.86 $\pm$ 0.016               & \textbf{0.87 $\pm$ 0.014}   \\
problem 5 & 0.80 $\pm$ 0.014            & 0.85 $\pm$ 0.023               & \textbf{0.86 $\pm$ 0.020}   \\ \hline
\end{tabular}
\end{table}

According to Table \ref{tab:hyperDynamic}, the experimental results show that in terms of convergence, the Reciprocal function produces the best result.
However, it also shows the disadvantage of the Reciprocal function, which can not provide a non-dominated set that covers the entire Pareto front. In contrast, the Quadratic function performs
slightly worse in convergence but obtains a good-coverage non-dominated set. The Linear function is dominated by Quadratic function in both aspects.

The better convergence with the Reciprocal function can be explained, as there is a minor change in threshold in the most generations and the swarm has a longer time to search along the same direction. On the other hand, with the Linear and Quadratic function, the constant changing in direction does not give the algorithm enough time to find a good solution.

Between the Quadratic function and the Linear function, their changing rate of threshold value is obviously different. The threshold value changes equally in each iteration with Linear function, while, with Quadratic function, the threshold changes little at the beginning and gradually become larger. As the swarm searches the low-cost region (as the threshold starts decreasing from 0.7) and gradually moves to high-cost region, it has more time to search in the low-cost region with the Quadratic function. This is the key reason that the performance with Quadratic function is better than with Linear function, because we have observed that the number of solutions in the low-cost region is much smaller than in the high-cost region, as shown in Figure \ref{fig:staticFunctions}, the low-cost regions are quite sparse compare with the high-cost regions. Therefore, it is reseaonable to give the algorithm more time to search the low-cost region, while, in the high-cost region, the algorithm can spend much less effort because the solutions are rich. As the Figure shows, generally, algorithm with Quadratic function obtains better solutions in the low-cost region than with Linear function.

% With these experiment results, we conclude that it is very problem-dependent to decide \emph{Which dynamic rounding function produces the best results}. In the web service location allocation problem, the solutions in the low-cost region is rare, therefore, it is reasonable to spent more iterations. In other problems, solutions might distribute differently. Therefore, a rational dynamic rounding function design should follow the domain knowledge of solution distribution. However, if there is no available knowledge, the linear function could be a reasonable baseline.
From table \ref{tab:hyperDynamic}, in terms of hypervolume, the Reciprocal function has the best performance. However, we can observe that the Reciprocal function can not provide a good coverage of the Pareto front in Figure \ref{fig:dynamicFunctions}. That is, the Reciprocal function missed many useful solutions because it lacks uniformity. Therefore, we can not determine which algorithm is better solely 
depend on the hypervolume values. We conclude that the Quadratic function performances the best even though in terms of hypervolume value, the Quadratic function is worse than the Reciprocal function. Mainly, because the disadvantage of reciprcol function is not neglectable.


\subsubsection{Results for the Stepped Rounding function}
We compared the performance of the stepped rounding function with the Reciprocal rounding function.
Table \ref{tab:transfercomp} clearly shows the Reciprocal function dominates the stepped threshold approach in most cases.
However, Figure \ref{fig:transfer} shows that the stepped rounding function dominates in Problem 3 and has better diversity in Problem 4.
The results indicate that another desired feature of the stepped rounding function. It could provide a uniformly distributed non-dominated set.
Overall, the performance of the stepped rounding function is very close to the Reciprocal function and almost the same with Quadratic function.

\begin{table}[]
\centering
\footnotesize
\caption{A comparison between Reciprocal function and Stepped function, the mean and standard deviation of hypervolume values over the 40 independent runs}
\label{tab:transfercomp}
\begin{tabular}{l|c|c}
\hline
                                                                                                            & Reciprocal                                                                                                                                     & Stepped                                                                                                                     \\ \hline
\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}problem 2\\ problem 3\\ problem 4\\ problem 5\end{tabular}} & \begin{tabular}[c]{@{}c@{}}\textbf{0.74 $\pm$ 0.013} \\ 0.815 $\pm$ 0.013\\ \textbf{0.87 $\pm$ 0.014} \\ \textbf{0.86 $\pm$ 0.020}  \end{tabular} & \begin{tabular}[c]{@{}c@{}}0.72 $\pm$ 0.011\\  \textbf{0.83 $\pm$ 0.014} \\ 0.85 $\pm$ 0.014\\ 0.85 $\pm$ 0.022\end{tabular} \\ \hline
\end{tabular}
\end{table}

\begin{figure}[h!]
   \centering
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/transfer_problem2.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/transfer_problem3.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/transfer_problem4.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/transfer_problem5.png}
    \caption{}
   \end{subfigure}
   \caption{Stepped Rounding Function Experiments: The non-dominated solutions among the sets obtained by 40 independent runs of stepped function and Reciprocal
   function}
   \label{fig:transfer}
\end{figure}


\subsubsection{Combination of Static Function}
In this experiment, we combined all solutions from 5 static rounding functions mentioned in Section \ref{sec:static_exp} and applied
a fast non-dominated sorting over it. The performance is compared with the Reciprocal rounding function in Figure \ref{fig:combination}.
As the figure shows, the combined non-dominated set dominates all the other results in all the problems. The solutions are not only diverse but also uniformly distributed.
However, the biggest trade-off is that this method takes five times longer than using the Reciprocal function.

\begin{figure}[h!]
   \centering
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/combination_problem2.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/combination_problem3.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/combination_problem4.png}
    \caption{}
   \end{subfigure}
   \begin{subfigure}{0.49\linewidth}
       \includegraphics[width=\textwidth]{pics/combination_problem5.png}
    \caption{}
   \end{subfigure}
   \caption{Combination of Static Function Experiments:  The non-dominated solutions among
the sets obtained by 40 independent runs of combination of static thresholds and Reciprocal
function}
   \label{fig:combination}
\end{figure}


\subsection{BMOPSOCD versus BNSPSO, NSGA-II, and BPSO}

To evaluate the performance of our proposed BMOPSOCD with dynamic function, we conduct experiments to compare its performance with three previous approaches, BNSPSO, BPSO, and NSGA-II. In the experiment, we use the Quadratic function as the rounding function. The results are shown in Table \ref{tab:results}. In this table, ``Ave-'', ``Std-'' illustrate the average and standard deviation of four approaches over the 40 independent runs. It can be seen from Table \ref{tab:results}, on all datasets except one, BMOPSOCD dominates other algorithms in both hypervolume and IGD. The only exception is Problem 1, where BPSO has the best hypervolume value. On all data sets, only BMOPSOCD remains an excellent performance on hypervolume while the performance of the other three approaches is apparently decreasing when the number of variables increases. On all data sets, BMOPSOCD achieved a considerably better performance than other three algorithms in IGD, which indicates that BMOPSOCD has a better coverage.

In comparison with BNSPSO and NSGA-II, BMOPSOCD with dynamic rounding function achieved significantly better convergence and diversity. The first reason is that with the dynamic
rounding function, BMOPSOCD could move out of local optima. In contrast, NSGA-II and BNSPSO are easy to be stuck at local optima. The second reason is the BMOPSOCD
keeps an external archive. Although the three algorithms maintain the same population, they produce different sizes of solutions. BMOPSOCD outputs an archive with a size of 250 while other two algorithms output a population of size 50.

In Problem 1, the convergence of BMOPSOCD is worse than that of BPSO. One reason is that BPSO runs 50 generations with the same weight for both objectives, it has more time to search on the same direction. On the other hand, with dynamic rounding function, MOSPCOD might not completely converge. Another reason is related to the problem size. BPSO has better performance in small datasets, when the number of datasets increases, the performance drops rapidly. In contrast, BMOPSOCD with the dynamic rounding function is not much affected by the number of variables.

\begin{table*}[!htb]
\centering
\footnotesize
\caption{Comparison between BMOPSOCD, BNSPSO, NSGA-II and BPSO: The non-dominated solutions among the sets obtained by 40 independent runs of different algorithms}
\label{tab:results}

\begin{tabular}{|c|l|c|c|}
\hline
Dataset                         & \multicolumn{1}{c|}{Method}                                              & Hypervolume (avg $\pm$ sd)                                                                                                     & \multicolumn{1}{l|}{IGD (avg $\pm$ sd)}                                                                                                    \\ \hline
problem 1                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}0.83 $\pm$ 0.04\\ 0.76 $\pm$ 0.018\\ 0.83 $\pm$ 0.013\\ \textbf{0.89 $\pm$ 0.015} \end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{3.73E-02 $\pm$ 1.03E-02} \\ 0.16 $\pm$ 3.45E-02\\  0.19 $\pm$ 3.21E-02\\ 0.46 $\pm$ 2.45E-02\end{tabular} \\ \hline
problem 2                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.73 $\pm$ 0.011} \\ 0.61 $\pm$ 0.001\\ 0.60 $\pm$ 0.011\\  0.61 $\pm$ 0.001\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{3.15E-02 $\pm$ 7.92E-03} \\ 0.15 $\pm$ 1.46E-02\\ 0.19 $\pm$ 1.81E-02\\  0.42 $\pm$ 1.54E-02\end{tabular} \\ \hline
problem 3                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.81 $\pm$ 0.012} \\ 0.61 $\pm$ 0.011\\ 0.59 $\pm$ 0.008\\ 0.69 $\pm$ 0.007\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{7.03E-03 $\pm$ 1.92E-03} \\ 0.10 $\pm$ 6.35E-03\\ 0.16 $\pm$ 7.25E-03\\  0.30 $\pm$ 8.94E-03\end{tabular} \\ \hline
problem 4                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.83 $\pm$ 0.016} \\ 0.63 $\pm$ 0.012\\ 0.61 $\pm$ 0.008\\ 0.71 $\pm$ 0.008\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{5.80E-03 $\pm$ 1.37E-03} \\ 0.11 $\pm$ 8.55E-03\\ 0.17 $\pm$ 9.11E-03 \\ 0.30 $\pm$ 8.62E-03\end{tabular} \\ \hline
problem 5                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.84 $\pm$ 0.014} \\ 0.61 $\pm$ 0.009\\ 0.58 $\pm$ 0.005\\ 0.67 $\pm$ 0.007\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{3.74E-03 $\pm$ 1.02E-03} \\ 0.11 $\pm$ 7.93E-03\\ 0.17 $\pm$ 6.89E-03\\  0.24 $\pm$ 5.02E-03\end{tabular} \\ \hline
\multicolumn{1}{|l|}{problem 6} & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.81 $\pm$ 0.014} \\ 0.59 $\pm$ 0.007\\ 0.55 $\pm$ 0.006\\ 0.63 $\pm$ 0.005\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{5.81E-03 $\pm$ 1.95E-03} \\ 0.11 $\pm$ 5.06E-03\\ 0.18 $\pm$ 8.01E-03 \\ 0.28 $\pm$ 5.88E-03\end{tabular} \\ \hline
problem 7                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.79 $\pm$ 0.015} \\ 0.60 $\pm$ 0.008\\ 0.56 $\pm$ 0.005\\ 0.63 $\pm$ 0.006\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{7.13E-03 $\pm$ 1.70E-03} \\ 0.10 $\pm$ 4.58E-03\\ 0.17 $\pm$ 6.48E-03 \\ 0.27 $\pm$ 7.92E-03\end{tabular} \\ \hline
problem 8                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.81 $\pm$ 0.015} \\ 0.61 $\pm$ 0.008\\ 0.58 $\pm$ 0.005\\ 0.65 $\pm$ 0.007\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{8.77E-03 $\pm$ 1.90E-03} \\ 0.12 $\pm$ 5.81E-03\\ 0.19 $\pm$ 6.17E-03 \\ 0.27 $\pm$ 5.86E-03\end{tabular} \\ \hline
problem 9                       & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.83 $\pm$ 0.016} \\ 0.60 $\pm$ 0.009\\ 0.56 $\pm$ 0.004\\ 0.62 $\pm$ 0.005\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{3.58E-03 $\pm$ 1.53E-03} \\ 0.11 $\pm$ 5.33E-03\\ 0.17 $\pm$ 3.56E-03 \\ 0.22 $\pm$ 3.22E-03\end{tabular} \\ \hline
problem 10                      & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.80 $\pm$ 0.012} \\ 0.58 $\pm$ 0.008\\ 0.53 $\pm$ 0.005\\ 0.58 $\pm$ 0.005\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{4.30E-03 $\pm$ 1.75E-03} \\ 0.11 $\pm$ 4.97E-03\\ 0.19 $\pm$ 5.62E-03 \\ 0.25 $\pm$ 3.91E-03\end{tabular} \\ \hline
problem 11                      & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.79 $\pm$ 0.012} \\ 0.57 $\pm$ 0.009\\ 0.52 $\pm$ 0.003\\ 0.55 $\pm$ 0.003\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{5.19E-03 $\pm$ 1.81E-03} \\ 0.12 $\pm$ 4.22E-03\\ 0.20 $\pm$ 2.74E-03 \\ 0.24 $\pm$ 3.36E-03\end{tabular} \\ \hline
problem 12                      & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.80 $\pm$ 0.01} \\ 0.58 $\pm$ 0.009\\ 0.52 $\pm$ 0.003\\ 0.56 $\pm$ 0.003\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{3.12E-03 $\pm$ 6.71E-04} \\ 0.12 $\pm$ 4.15E-03\\ 0.20 $\pm$ 3.08E-03 \\ 0.24 $\pm$ 2.50E-03\end{tabular} \\ \hline
problem 13                      & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.83 $\pm$ 0.012} \\ 0.59 $\pm$ 0.008\\ 0.53 $\pm$ 0.003\\ 0.56 $\pm$ 0.004\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{2.63E-03 $\pm$ 6.73E-04} \\ 0.12 $\pm$ 3.46E-03\\ 0.20 $\pm$ 3.04E-03 \\ 0.22 $\pm$ 2.01E-03\end{tabular} \\ \hline
problem 14                      & \begin{tabular}[c]{@{}l@{}}BMOPSOCD\\ BNSPSO\\ NSGA-II\\ BPSO\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{0.84 $\pm$ 0.015} \\ 0.59 $\pm$ 0.009\\ 0.53 $\pm$ 0.002\\ 0.57 $\pm$ 0.003\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{3.66E-03 $\pm$ 1.75E-03} \\ 0.13 $\pm$ 3.85E-03\\ 0.22 $\pm$ 3.24E-03 \\ 0.25 $\pm$ 1.83E-03\end{tabular} \\ \hline
\end{tabular}

\end{table*}

Regarding execution time, BMOPSOCD is much better than other PSO variations. It achieves the best or the second best performance for 11 out of 14
problems (Table \ref{tab:time}).


\begin{table*}[th]
\centering
\footnotesize
\caption{Execution time (seconds)}
\label{tab:time}
\scalebox{0.9}{

\begin{subtable}{.43\textwidth}
\centering
\begin{tabular}{|l|c|c|}
\hline
           & method                                                                   & time (avg $\pm$ sd)                                                                                                                           \\ \hline
problem 1  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}17.99 $\pm$ 0.26 \\ \textbf{12.98 $\pm$ 0.18}\\ 19.00 $\pm$ 0.17 \\ 15.35 $\pm$ 0.15\end{tabular}                    \\ \hline
problem 2  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}23.55 $\pm$ 0.27 \\ 16.18 $\pm$ 0.26\\ 25.52 $\pm$ 0.27 \\ \textbf{15.38 $\pm$ 0.31}\end{tabular}                    \\ \hline
problem 3  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}103.65 $\pm$ 1.87 \\ 94.98 $\pm$ 7.28 \\ 111.86 $\pm$ 1.11 \\ \textbf{74.34 $\pm$ 0.61}\end{tabular}                 \\ \hline
problem 4  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}181.20 $\pm$ 4.40 \\ 175.99 $\pm$ 9.67 \\ 182.09 $\pm$ 1.86 \\ \textbf{147.98 $\pm$ 1.30}\end{tabular}               \\ \hline
problem 5  & \begin{tabular}[c]{@{}c@{}}BPSO\\ MOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}137.03 $\pm$ 0.87 \\ 89.74 $\pm$ 8.53 \\ 161.31 $\pm$ 0.95 \\ \textbf{84.17 $\pm$ 1.03}\end{tabular}                 \\ \hline
problem 6  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}208.63 $\pm$ 2.23 \\ 172.80 $\pm$ 7.68 \\ 236.23 $\pm$ 2.72 \\ \textbf{157.52$\pm$ 1.62}\end{tabular}                \\ \hline
problem 7  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}234.73 $\pm$ 6.42 \\ 202.68 $\pm$ 10.46 \\ 242.94 $\pm$ 9.00 \\ \textbf{159.26 $\pm$ 1.31}\end{tabular}              \\ \hline
\end{tabular}
\end{subtable}

\begin{subtable}{.43\linewidth}
\centering
\begin{tabular}{|l|c|c|}
\hline
           & method                                                                   & time (avg $\pm$ sd)                                                                                                                           \\ \hline
problem 8  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}476.76 $\pm$ 22.40 \\ 531.64 $\pm$ 43.14 \\ 444.41 $\pm$ 22.86 \\ \textbf{375.05 $\pm$ 4.11}\end{tabular}            \\ \hline
problem 9  & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}293.43 $\pm$ 3.01 \\ 198.81 $\pm$ 7.11 \\ 334.62 $\pm$ 2.81 \\ \textbf{181.30 $\pm$ 1.99}\end{tabular}               \\ \hline
problem 10 & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}507.72 $\pm$ 4.19 \\ 449.91 $\pm$ 26.00 \\ 539.51 $\pm$ 4.06 \\ \textbf{381.18 $\pm$ 3.06}\end{tabular}              \\ \hline
problem 11 & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}1,237.30 $\pm$ 42.06 \\ 1,262.79 $\pm$ 91.65\\ 1,328.17 $\pm$ 12.67 \\ \textbf{1,036.53 $\pm$ 35.38}\end{tabular}    \\ \hline
problem 12 & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}3,631.14 $\pm$ 17.70 \\ 4,326.22 $\pm$ 478.14 \\ 3,395.47 $\pm$ 100.51 \\ \textbf{3,326.94 $\pm$ 38.21}\end{tabular} \\ \hline
problem 13 & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}1,416.63 $\pm$ 0.26 \\ 1,155.21 $\pm$ 28.85 \\ 1,507.92 $\pm$ 25.74 \\ \textbf{1,098.08 $\pm$ 17.36}\end{tabular}    \\ \hline
problem 14 & \begin{tabular}[c]{@{}c@{}}BPSO\\ BMOPSOCD\\ BNSPSO\\ NSGA-II\end{tabular} & \begin{tabular}[c]{@{}c@{}}3,617.53 $\pm$ 34.13 \\ \textbf{3,284.66 $\pm$ 124.13} \\ 3,759.51$\pm$ 61.49 \\ 3,372.53 $\pm$ 31.05 \end{tabular}   \\ \hline
\end{tabular}
\end{subtable}
}
\end{table*}





\begin{figure*}[ht]
   \caption{MOPSOCD, BNSPSO, and BPSO Experiments: The non-dominated solutions
among the sets obtained by 40 independent runs of different algorithms}
   \centering
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total1.png}
    \caption{Problem 1}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total2.png}
    \caption{Problem 2}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total3.png}
    \caption{Problem 3}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total4.png}
    \caption{Problem 4}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total5.png}
    \caption{Problem 5}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total6.png}
    \caption{Problem 6}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total7.png}
    \caption{Problem 7}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total8.png}
    \caption{Problem 8}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total9.png}
    \caption{Problem 9}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total10.png}
    \caption{Problem 10}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total11.png}
    \caption{Problem 11}
   \end{subfigure}
   \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total12.png}
    \caption{Problem 12}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total13.png}
    \caption{Problem 13}
   \end{subfigure}
      \begin{subfigure}{0.25\linewidth}
       \includegraphics[width=\textwidth]{pics/total14.png}
    \caption{Problem 14}
   \end{subfigure}
   \label{fig:total}
\end{figure*}

In summary, from the experimental evaluation comparing the proposed algorithm with previous approaches, we observe that on most datasets, BMOPSOCD can achieve much better results in both convergence and diversity than other three methods, BNSPSO, NSGA-II, and BPSO. Additionally, the performance of MOPSOCD with dynamic rounding function is not affected by the number of variables. This is a significant advantage of BMOPSOCD over the other three approaches.

\section{Conclusion and Future Work} \label{sec:conclution}

This paper proposed a BMOPSOCD to solve the WSLA problem with the aim of producing a set of high-quality solutions with good diversity that covers most of the Pareto front when dealing with large datasets. For that, we proposed a binary version of multi-objective PSO with crowding distance to solve the WSLA problem. We introduce a rounding function mechanism which not only makes a continuous algorithm compatible with binary problems but also significantly improves the quality of solutions. Specifically, three types of rounding functions were developed. From the experiments, we observed that the solutions obtained by BMOPSOCD with dynamic rounding functions have a great diversity that almost covers the whole Pareto front. Meanwhile, BMOPSOCD could produce good solutions regardless of the increasing problem size.

%The major contribution is that we provide a rounding function and an adaptive threshold technique to make a continuous algorithm compatible with a binary problem. These techniques can also be applied in other continuous algorithms. We have shown that BMOPSOCD can produce solutions with a good diversity that covers most of the Pareto front.

There are a few directions that future work that we can work on. Firstly, our model can be further improved by considering service composition. For now, the problem model considers each service as an atomic service. With the increasing usages of composite services composed with atomic services distributed over the Internet, we need to consider service composition workflow while doing WSLA.   Service composition workflows have a significant impact on the allocation of atomic services because the data flow between services could not be neglected. Therefore, the location of each atomic service is highly related to the previous and the next service in a workflow.

Secondly, more potential objectives need to be considered, for example, the availability problem. To avoid single point failure, web service providers normally deploy multiple services in different candidate locations to keep the availability. Green economy could also be considered. As the issue of global warming becomes a global challenge, deploying a service to a location that is closed to a power plant has been proposed in the literature \cite{Schien}. In addition, future work can consider multiple constraints such as the overall cost constraints and bandwidth constraints.

%\ifCLASSOPTIONcaptionsoff
 %\newpage
%\fi

\bibliographystyle{IEEEtran}

\bibliography{sample}

\end{document}






% The rounding process can be done in fitness function so that there is no need to modify the PSO.

% We introduced a \emph{service location-allocation probability matrix}, $A' = [a'_{sj}]$ represents the probability of a
% service $s_{i}$ allocate to a candidate location $j_{i}$.
% $a'_{sj}$ is a real-valued, $a'_{sj} \in (0, 1)$ indicate the probability of a service is \textbf{NOT}
% allocate to a candidate location.
%
% We use the service location-allocation probability matrix $A'$ = $[a'_{sj}]$ as a particle.
% During the PSO process, the particle needs to be transfered to binary representation in order to compatible with
% the modeling. In order to transfer $A' \rightarrow A$, we introduced a transformation
% function.
%







